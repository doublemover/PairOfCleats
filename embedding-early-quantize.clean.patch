diff --git a/src/index/build/file-processor/embeddings.js b/src/index/build/file-processor/embeddings.js
--- a/src/index/build/file-processor/embeddings.js
+++ b/src/index/build/file-processor/embeddings.js
@@ -1,6 +1,11 @@
-import { normalizeVec } from '../../embedding.js';
+import { normalizeVec, quantizeVecUint8 } from '../../embedding.js';
 import { resolveEmbeddingBatchSize } from '../embedding-batch.js';
 
+// Empty marker used throughout the indexing pipeline to indicate a missing doc vector.
+// Downstream code treats a zero-length Uint8Array as "missing doc" and substitutes a
+// shared zero-vector for dot products without allocating per-chunk.
+const EMPTY_U8 = new Uint8Array(0);
+
 export async function attachEmbeddings({
   chunks,
   codeTexts,
@@ -86,6 +91,28 @@
   // Most code chunks have no doc payload; allocating `dims` zeros for each chunk
   // is a major memory multiplier for large indexes.
   const missingDoc = [];
+
+  // Capture a best-effort dimension hint for missing vectors so we can still emit
+  // fixed-length byte vectors for every chunk. If a chunk ends up with no code/doc
+  // embedding (e.g., upstream service failure), we store a shared "zero" byte vector
+  // instead of an empty one to keep downstream consumers consistent.
+  let dimsHint = 0;
+  for (const v of codeVectors || []) {
+    if (Array.isArray(v) && v.length) {
+      dimsHint = v.length;
+      break;
+    }
+  }
+  if (!dimsHint) {
+    for (const v of docVectors || []) {
+      if (Array.isArray(v) && v.length) {
+        dimsHint = v.length;
+        break;
+      }
+    }
+  }
+  const zeroU8 = dimsHint ? new Uint8Array(dimsHint).fill(128) : EMPTY_U8;
+
   for (let i = 0; i < chunks.length; i += 1) {
     const chunk = chunks[i];
     const embedCode = Array.isArray(codeVectors[i]) ? codeVectors[i] : [];
@@ -97,9 +124,26 @@
         ? embedCode.map((v, idx) => (v + (rawDoc[idx] ?? 0)) / 2)
         : embedCode)
       : (hasDoc ? rawDoc : missingDoc);
-    chunk.embed_code = embedCode;
-    chunk.embed_doc = embedDoc;
-    chunk.embedding = normalizeVec(merged);
+
+    // Normalize + quantize immediately. Holding full float embeddings for every chunk
+    // dramatically increases peak heap usage during indexing.
+    const mergedNorm = merged.length ? normalizeVec(merged) : null;
+    const mergedU8 = mergedNorm && mergedNorm.length ? quantizeVecUint8(mergedNorm) : zeroU8;
+    const codeU8 = embedCode.length ? quantizeVecUint8(embedCode) : mergedU8;
+    const docU8 = hasDoc ? quantizeVecUint8(rawDoc) : EMPTY_U8;
+
+    chunk.embedding_u8 = mergedU8;
+    chunk.embed_code_u8 = codeU8;
+    chunk.embed_doc_u8 = docU8;
+
+    // Drop float vectors to avoid retaining large arrays in the long-lived build state.
+    delete chunk.embed_code;
+    delete chunk.embed_doc;
+    delete chunk.embedding;
+
+    // Help GC by clearing references from the per-file vector arrays.
+    if (Array.isArray(codeVectors)) codeVectors[i] = null;
+    docVectors[i] = null;
   }
 
   return { embeddingMs: Date.now() - embedStart };
