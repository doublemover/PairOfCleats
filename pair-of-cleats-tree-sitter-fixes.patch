diff --git a/src/index/chunking/dispatch.js b/src/index/chunking/dispatch.js
index a1de56c..df70aa1 100644
--- a/src/index/chunking/dispatch.js
+++ b/src/index/chunking/dispatch.js
@@ -485,7 +485,7 @@ const CODE_CHUNKERS = [
   { id: 'html', match: (ext) => isHtml(ext), chunk: ({ text, context }) =>
     context?.htmlChunks || buildHtmlChunks(text, getTreeSitterOptions(context)) },
   { id: 'css', match: (ext) => isCss(ext), chunk: ({ text, context }) =>
-    context?.cssChunks || buildCssChunks(text) },
+    context?.cssChunks || buildCssChunks(text, getTreeSitterOptions(context)) },
   { id: 'python', match: (ext) => ext === '.py', chunk: ({ text, context }) => {
     const astChunks = buildPythonChunksFromAst(text, context?.pythonAst || null);
     if (astChunks && astChunks.length) return astChunks;
diff --git a/src/index/language-registry/registry.js b/src/index/language-registry/registry.js
index 7c6da56..ddcf261 100644
--- a/src/index/language-registry/registry.js
+++ b/src/index/language-registry/registry.js
@@ -330,7 +330,7 @@ const LANGUAGE_REGISTRY = [
     id: 'css',
     match: (ext) => isCss(ext),
     collectImports: (text) => collectCssImports(text),
-    prepare: ({ text, mode }) => (mode === 'code' ? { cssChunks: buildCssChunks(text) } : {}),
+    prepare: ({ text, mode, options }) => (mode === 'code' ? { cssChunks: buildCssChunks(text, options) } : {}),
     buildRelations: ({ text, allImports }) => buildCssRelations(text, allImports),
     extractDocMeta: ({ chunk }) => extractCssDocMeta(chunk),
     flow: () => computeCssFlow(),
diff --git a/src/lang/css.js b/src/lang/css.js
index 46ab262..f0038fa 100644
--- a/src/lang/css.js
+++ b/src/lang/css.js
@@ -2,6 +2,7 @@ import { buildLineIndex, offsetToLine } from '../shared/lines.js';
 import { extractDocComment, sliceSignature } from './shared.js';
 import { getTreeSitterParser } from './tree-sitter.js';
 import { getNamedChild, getNamedChildCount } from './tree-sitter/ast.js';
+import { isTreeSitterEnabled } from './tree-sitter/options.js';
 
 const RULE_NODES = new Set([
   'rule_set',
@@ -12,6 +13,97 @@ const RULE_NODES = new Set([
   'at_rule'
 ]);
 
+const loggedParseTimeouts = new Set();
+const loggedSizeSkips = new Set();
+const loggedTraversalBudget = new Set();
+const loggedUnavailable = new Set();
+
+// Guardrails: CSS can contain extremely large selector lists or nested at-rules.
+// Keep traversal and chunk extraction bounded to avoid pathological memory / CPU usage.
+const DEFAULT_MAX_AST_NODES = 250_000;
+const DEFAULT_MAX_AST_STACK = 250_000;
+const DEFAULT_MAX_CHUNK_NODES = 5_000;
+
+function countLines(text) {
+  if (!text) return 0;
+  let count = 1;
+  for (let i = 0; i < text.length; i += 1) {
+    if (text.charCodeAt(i) === 10) count += 1;
+  }
+  return count;
+}
+
+const createLineAccessor = (text, lineIndex) => {
+  const index = Array.isArray(lineIndex) ? lineIndex : buildLineIndex(text);
+  const lineCount = index.length;
+  return {
+    length: lineCount,
+    getLine: (idx) => {
+      if (!Number.isFinite(idx) || idx < 0 || idx >= lineCount) return '';
+      const start = index[idx] ?? 0;
+      const end = index[idx + 1] ?? text.length;
+      let line = text.slice(start, end);
+      if (line.endsWith('\n')) line = line.slice(0, -1);
+      if (line.endsWith('\r')) line = line.slice(0, -1);
+      return line;
+    }
+  };
+};
+
+function resolveTraversalBudget(options) {
+  const config = options?.treeSitter || {};
+  const perLanguage = config.byLanguage?.css || {};
+  const maxAstNodes = perLanguage.maxAstNodes ?? config.maxAstNodes ?? DEFAULT_MAX_AST_NODES;
+  const maxAstStack = perLanguage.maxAstStack ?? config.maxAstStack ?? DEFAULT_MAX_AST_STACK;
+  const maxChunkNodes = perLanguage.maxChunkNodes ?? config.maxChunkNodes ?? DEFAULT_MAX_CHUNK_NODES;
+  return {
+    maxAstNodes: Number.isFinite(maxAstNodes) && maxAstNodes > 0 ? Math.floor(maxAstNodes) : DEFAULT_MAX_AST_NODES,
+    maxAstStack: Number.isFinite(maxAstStack) && maxAstStack > 0 ? Math.floor(maxAstStack) : DEFAULT_MAX_AST_STACK,
+    maxChunkNodes: Number.isFinite(maxChunkNodes) && maxChunkNodes > 0 ? Math.floor(maxChunkNodes) : DEFAULT_MAX_CHUNK_NODES
+  };
+}
+
+function exceedsTreeSitterLimits(text, options) {
+  const config = options?.treeSitter || {};
+  const perLanguage = config.byLanguage?.css || {};
+  const maxBytes = perLanguage.maxBytes ?? config.maxBytes;
+  const maxLines = perLanguage.maxLines ?? config.maxLines;
+
+  if (typeof maxBytes === 'number' && maxBytes > 0) {
+    const bytes = Buffer.byteLength(text, 'utf8');
+    if (bytes > maxBytes) {
+      const key = 'css:bytes';
+      if (!loggedSizeSkips.has(key) && options?.log) {
+        options.log(`Tree-sitter disabled for css; file exceeds maxBytes (${bytes} > ${maxBytes}).`);
+        loggedSizeSkips.add(key);
+      }
+      return true;
+    }
+  }
+
+  if (typeof maxLines === 'number' && maxLines > 0) {
+    const lines = countLines(text);
+    if (lines > maxLines) {
+      const key = 'css:lines';
+      if (!loggedSizeSkips.has(key) && options?.log) {
+        options.log(`Tree-sitter disabled for css; file exceeds maxLines (${lines} > ${maxLines}).`);
+        loggedSizeSkips.add(key);
+      }
+      return true;
+    }
+  }
+
+  return false;
+}
+
+function resolveParseTimeoutMs(options) {
+  const config = options?.treeSitter || {};
+  const perLanguage = config.byLanguage?.css || {};
+  const raw = perLanguage.maxParseMs ?? config.maxParseMs;
+  const parsed = Number(raw);
+  return Number.isFinite(parsed) && parsed > 0 ? Math.floor(parsed) : null;
+}
+
 function extractRuleName(text, node) {
   const limit = Math.min(node.endIndex, node.startIndex + 240);
   const slice = text.slice(node.startIndex, limit);
@@ -23,19 +115,43 @@ function extractRuleName(text, node) {
   return slice.slice(0, cutoff).replace(/\s+/g, ' ').trim();
 }
 
-function gatherRuleNodes(root) {
+function gatherRuleNodes(root, budget) {
   const nodes = [];
   const stack = [root];
+  let visited = 0;
+  const maxAstNodes = budget?.maxAstNodes ?? DEFAULT_MAX_AST_NODES;
+  const maxAstStack = budget?.maxAstStack ?? DEFAULT_MAX_AST_STACK;
+  const maxChunkNodes = budget?.maxChunkNodes ?? DEFAULT_MAX_CHUNK_NODES;
+
   while (stack.length) {
+    if (stack.length > maxAstStack) {
+      return { nodes: null, reason: 'maxAstStack', visited, matched: nodes.length };
+    }
     const node = stack.pop();
     if (!node) continue;
+
+    visited += 1;
+    if (visited > maxAstNodes) {
+      return { nodes: null, reason: 'maxAstNodes', visited, matched: nodes.length };
+    }
+
     const missing = typeof node.isMissing === 'function' ? node.isMissing() : node.isMissing;
     if (missing) continue;
-    if (RULE_NODES.has(node.type)) nodes.push(node);
+
+    if (RULE_NODES.has(node.type)) {
+      nodes.push(node);
+      if (nodes.length > maxChunkNodes) {
+        return { nodes: null, reason: 'maxChunkNodes', visited, matched: nodes.length };
+      }
+    }
+
     const count = getNamedChildCount(node);
-    for (let i = count - 1; i >= 0; i -= 1) stack.push(getNamedChild(node, i));
+    for (let i = count - 1; i >= 0; i -= 1) {
+      stack.push(getNamedChild(node, i));
+    }
   }
-  return nodes;
+
+  return { nodes, reason: null, visited, matched: nodes.length };
 }
 
 export function collectCssImports(text) {
@@ -47,73 +163,133 @@ export function collectCssImports(text) {
   return Array.from(imports);
 }
 
-export function buildCssChunks(text) {
-  const parser = getTreeSitterParser('css');
-  if (!parser) return buildCssHeuristicChunks(text);
+export function buildCssChunks(text, options = {}) {
+  // If the caller provides tree-sitter options, respect enable/disable toggles.
+  if (options?.treeSitter && !isTreeSitterEnabled(options, 'css')) {
+    return buildCssHeuristicChunks(text, options);
+  }
+  if (exceedsTreeSitterLimits(text, options)) {
+    return buildCssHeuristicChunks(text, options);
+  }
+
+  const parser = getTreeSitterParser('css', options);
+  if (!parser) {
+    if (options?.log && !loggedUnavailable.has('css')) {
+      options.log('Tree-sitter unavailable for css; falling back to heuristic chunking.');
+      loggedUnavailable.add('css');
+    }
+    return buildCssHeuristicChunks(text, options);
+  }
+
+  const traversalBudget = resolveTraversalBudget(options);
   let tree = null;
+
   try {
     try {
+      const parseTimeoutMs = resolveParseTimeoutMs(options);
+      if (typeof parser.setTimeoutMicros === 'function') {
+        parser.setTimeoutMicros(parseTimeoutMs ? parseTimeoutMs * 1000 : 0);
+      }
       tree = parser.parse(text);
-      const rootNode = tree?.rootNode;
-      if (!rootNode) return buildCssHeuristicChunks(text);
-      const nodes = gatherRuleNodes(rootNode);
-      if (!nodes.length) return buildCssHeuristicChunks(text);
-      const lineIndex = buildLineIndex(text);
-      const lines = text.split('\n');
-      const chunks = [];
-      for (const node of nodes) {
-        const name = extractRuleName(text, node);
-        if (!name) continue;
-        const start = node.startIndex;
-        const end = node.endIndex;
-        const startLine = offsetToLine(lineIndex, start);
-        const endLine = offsetToLine(lineIndex, Math.max(start, end - 1));
-        const signature = sliceSignature(text, start, Math.min(end, start + 240));
-        const docstring = extractDocComment(lines, startLine - 1, {
-          blockStarts: ['/**', '/*']
-        });
-        chunks.push({
-          start,
-          end,
-          name,
-          kind: 'StyleRule',
-          meta: {
-            startLine,
-            endLine,
-            signature,
-            docstring
-          }
-        });
+    } catch (err) {
+      const message = err?.message || String(err);
+      if (/timeout/i.test(message)) {
+        if (options?.log && !loggedParseTimeouts.has('css')) {
+          options.log('Tree-sitter parse timed out for css; falling back to heuristic chunking.');
+          loggedParseTimeouts.add('css');
+        }
       }
-      if (!chunks.length) return null;
-      chunks.sort((a, b) => a.start - b.start);
-      return chunks;
-    } catch {
-      return buildCssHeuristicChunks(text);
+      return buildCssHeuristicChunks(text, options);
+    }
+
+    const rootNode = tree?.rootNode || null;
+    if (!rootNode) return buildCssHeuristicChunks(text, options);
+
+    const result = gatherRuleNodes(rootNode, traversalBudget);
+    if (!result?.nodes) {
+      const key = `css:${result?.reason || 'budget'}`;
+      if (options?.log && !loggedTraversalBudget.has(key)) {
+        options.log(
+          `Tree-sitter traversal aborted for css (${result?.reason}); `
+            + `visited=${result?.visited ?? 'n/a'} matched=${result?.matched ?? 'n/a'}. `
+            + 'Falling back to heuristic chunking.'
+        );
+        loggedTraversalBudget.add(key);
+      }
+      return buildCssHeuristicChunks(text, options);
+    }
+
+    const nodes = result.nodes;
+    if (!nodes.length) return buildCssHeuristicChunks(text, options);
+
+    const lineIndex = buildLineIndex(text);
+    const lineAccessor = createLineAccessor(text, lineIndex);
+    const chunks = [];
+
+    for (const node of nodes) {
+      const name = extractRuleName(text, node);
+      if (!name) continue;
+
+      const start = node.startIndex;
+      const end = node.endIndex;
+      const startLine = offsetToLine(lineIndex, start);
+      const endLine = offsetToLine(lineIndex, Math.max(start, end - 1));
+      const signature = sliceSignature(text, start, Math.min(end, start + 240));
+      const docstring = extractDocComment(lineAccessor, startLine - 1, {
+        blockStarts: ['/**', '/*']
+      });
+
+      chunks.push({
+        start,
+        end,
+        name,
+        kind: 'StyleRule',
+        meta: {
+          startLine,
+          endLine,
+          signature,
+          docstring
+        }
+      });
     }
+
+    if (!chunks.length) return buildCssHeuristicChunks(text, options);
+    chunks.sort((a, b) => a.start - b.start);
+    return chunks;
   } finally {
+    // web-tree-sitter `Tree` objects hold WASM-backed memory and must be explicitly released.
     try {
       if (tree && typeof tree.delete === 'function') tree.delete();
     } catch {
       // ignore disposal failures
     }
+
+    // Reset parser state to avoid unbounded growth of internal allocations.
+    try {
+      if (parser && typeof parser.reset === 'function') parser.reset();
+    } catch {
+      // ignore reset failures
+    }
   }
 }
 
-function buildCssHeuristicChunks(text) {
+function buildCssHeuristicChunks(text, options = {}) {
   const chunks = [];
   const lineIndex = buildLineIndex(text);
-  const lines = text.split('\n');
+  const lineAccessor = createLineAccessor(text, lineIndex);
+
   let idx = 0;
   while (idx < text.length) {
     const brace = text.indexOf('{', idx);
     if (brace === -1) break;
+
     const selectorStart = Math.max(text.lastIndexOf('\n', brace), text.lastIndexOf('\r', brace)) + 1;
     const selector = text.slice(selectorStart, brace).trim();
     if (!selector) {
       idx = brace + 1;
       continue;
     }
+
     let depth = 0;
     let end = brace;
     for (; end < text.length; end += 1) {
@@ -127,16 +303,18 @@ function buildCssHeuristicChunks(text) {
         }
       }
     }
+
     const start = selectorStart;
     const endIdx = Math.min(text.length, end);
     const startLine = offsetToLine(lineIndex, start);
     const endLine = offsetToLine(lineIndex, Math.max(start, endIdx - 1));
     const signature = sliceSignature(text, start, Math.min(endIdx, start + 240));
-    const docstring = extractDocComment(lines, startLine - 1, {
+    const docstring = extractDocComment(lineAccessor, startLine - 1, {
       linePrefixes: ['/*', '/**'],
       blockStarts: ['/*', '/**'],
       blockEnd: '*/'
     });
+
     chunks.push({
       start,
       end: endIdx,
@@ -149,13 +327,23 @@ function buildCssHeuristicChunks(text) {
         endLine
       }
     });
+
     idx = endIdx;
   }
+
   return chunks.length ? chunks : null;
 }
 
 export function buildCssRelations(text, allImports) {
-  return { imports: collectCssImports(text), exports: [], calls: [], usages: [], importLinks: [], functionMeta: {}, classMeta: {} };
+  return {
+    imports: collectCssImports(text),
+    exports: [],
+    calls: [],
+    usages: [],
+    importLinks: [],
+    functionMeta: {},
+    classMeta: {}
+  };
 }
 
 export function extractCssDocMeta(chunk) {
diff --git a/src/lang/html.js b/src/lang/html.js
index 8eb3f0c..b4b104d 100644
--- a/src/lang/html.js
+++ b/src/lang/html.js
@@ -228,10 +228,10 @@ const EMBEDDED_CHUNKERS = new Map([
   ['toml', (text) => chunkIniToml(text, 'toml')],
   ['ini', (text) => chunkIniToml(text, 'ini')],
   ['markdown', (text) => chunkMarkdown(text)],
-  ['css', (text) => buildCssChunks(text) || null],
-  ['scss', (text) => buildCssChunks(text) || null],
-  ['sass', (text) => buildCssChunks(text) || null],
-  ['less', (text) => buildCssChunks(text) || null],
+  ['css', (text, options) => buildCssChunks(text, options) || null],
+  ['scss', (text, options) => buildCssChunks(text, options) || null],
+  ['sass', (text, options) => buildCssChunks(text, options) || null],
+  ['less', (text, options) => buildCssChunks(text, options) || null],
   ['shell', (text) => buildShellChunks(text)],
   ['c', (text, options) => buildCLikeChunks(text, '.c', options)],
   ['cpp', (text, options) => buildCLikeChunks(text, '.cpp', options)],
diff --git a/src/lang/tree-sitter/chunking.js b/src/lang/tree-sitter/chunking.js
index 3f28b2b..77405a6 100644
--- a/src/lang/tree-sitter/chunking.js
+++ b/src/lang/tree-sitter/chunking.js
@@ -119,53 +119,51 @@ function extractSignature(text, start, end) {
   return sliceSignature(text, start, endIdx).replace(/\s+/g, ' ').trim();
 }
 
+const DEFAULT_NAME_SEARCH_MAX_DEPTH = 6;
+const DEFAULT_NAME_SEARCH_MAX_NODES = 128;
+
 function findNameNode(node, config) {
-  if (!node) return null;
-  const direct = node.childForFieldName('name');
-  if (direct) return direct;
-  const fieldNames = Array.isArray(config?.nameFields) ? config.nameFields : [];
-  for (const field of fieldNames) {
-    const child = node.childForFieldName(field);
-    if (child) return child;
-  }
-  const nameTypes = config?.nameNodeTypes || COMMON_NAME_NODE_TYPES;
-  const declarator = node.childForFieldName('declarator');
-  if (declarator) {
-    const named = findDescendantByType(declarator, nameTypes, 8);
-    if (named) return named;
-  }
-  // Depth-limited breadth-first search for a reasonable name node.
-  // Avoid Array#shift() here (O(n) per operation) to keep this path cheap.
-  const queue = [];
-  const depths = [];
+  const nameTypes = config?.nameTypes;
+  if (!nameTypes || !nameTypes.size || !node) return null;
+
+  // Traversal limits: names should be close to the declaration node, but some grammars
+  // wrap identifiers a few levels deep. Keep this bounded and deterministic.
+  const maxDepth = Number.isFinite(config?.nameSearchMaxDepth)
+    ? Math.max(1, Math.floor(config.nameSearchMaxDepth))
+    : DEFAULT_NAME_SEARCH_MAX_DEPTH;
+
+  const maxNodes = Number.isFinite(config?.nameSearchMaxNodes)
+    ? Math.max(1, Math.floor(config.nameSearchMaxNodes))
+    : DEFAULT_NAME_SEARCH_MAX_NODES;
+
+  let frontier = [];
   const initialCount = getNamedChildCount(node);
   for (let i = 0; i < initialCount; i += 1) {
     const child = getNamedChild(node, i);
-    if (!child) continue;
-    queue.push(child);
-    depths.push(1);
+    if (child) frontier.push(child);
   }
-  for (let q = 0; q < queue.length; q += 1) {
-    const next = queue[q];
-    const depth = depths[q] || 1;
-    if (!next) continue;
-    if (nameTypes.has(next.type)) return next;
-    if (depth >= 4) continue;
-    const childCount = getNamedChildCount(next);
-    for (let i = 0; i < childCount; i += 1) {
-      const child = getNamedChild(next, i);
-      if (!child) continue;
-      queue.push(child);
-      depths.push(depth + 1);
+
+  let visited = 0;
+  for (let depth = 1; depth <= maxDepth && frontier.length; depth += 1) {
+    const nextFrontier = [];
+
+    for (const next of frontier) {
+      if (!next) continue;
+      visited += 1;
+      if (nameTypes.has(next.type)) return next;
+      if (visited >= maxNodes) return null;
+
+      const childCount = getNamedChildCount(next);
+      for (let i = 0; i < childCount; i += 1) {
+        const child = getNamedChild(next, i);
+        if (child) nextFrontier.push(child);
+      }
     }
+
+    frontier = nextFrontier;
   }
-  return null;
-}
 
-function extractNodeName(node, text, config) {
-  const nameNode = findNameNode(node, config);
-  if (!nameNode) return '';
-  return text.slice(nameNode.startIndex, nameNode.endIndex).trim();
+  return null;
 }
 
 function findNearestType(node, config) {
@@ -392,8 +390,7 @@ export function buildTreeSitterChunks({ text, languageId, ext, options }) {
     // Some tree-sitter builds retain internal parse stack allocations across parses.
     // Resetting keeps memory bounded across long-running indexing jobs.
     try {
-      const parserRef = treeSitterState?.parserCache?.get?.(resolvedId);
-      if (parserRef && typeof parserRef.reset === 'function') parserRef.reset();
+      if (parser && typeof parser.reset === 'function') parser.reset();
     } catch {
       // ignore reset failures
     }
@@ -401,33 +398,53 @@ export function buildTreeSitterChunks({ text, languageId, ext, options }) {
 }
 
 export async function buildTreeSitterChunksAsync({ text, languageId, ext, options }) {
+  // If tree-sitter is disabled (or no config provided), keep the synchronous behavior.
   if (!options?.treeSitter || options.treeSitter.enabled === false) {
     return buildTreeSitterChunks({ text, languageId, ext, options });
   }
+
+  const resolvedId = resolveLanguageForExt(languageId, ext);
+  if (!resolvedId) return null;
+
+  // Avoid spinning up / dispatching to workers when we already know we will skip tree-sitter.
+  if (!isTreeSitterEnabled(options, resolvedId)) return null;
+  if (exceedsTreeSitterLimits(text, options, resolvedId)) return null;
+  if (!LANG_CONFIG[resolvedId]) return null;
+
   const pool = await getTreeSitterWorkerPool(options?.treeSitter?.worker, options);
   if (!pool) {
     return buildTreeSitterChunks({ text, languageId, ext, options });
   }
-  const resolvedId = resolveLanguageForExt(languageId, ext) || languageId || 'unknown';
+
   const metricsCollector = options?.metricsCollector;
   const shouldRecordMetrics = metricsCollector && typeof metricsCollector.add === 'function';
   const lineCount = shouldRecordMetrics ? countLines(text) : 0;
   const metricsStart = shouldRecordMetrics ? Date.now() : 0;
+
   const payload = {
     text,
     languageId,
     ext,
     treeSitter: sanitizeTreeSitterOptions(options?.treeSitter)
   };
+
+  // Avoid double-counting tree-sitter metrics when falling back to in-thread parsing.
+  const fallbackOptions = shouldRecordMetrics
+    ? { ...options, metricsCollector: null }
+    : options;
+
   try {
     const result = await pool.run(payload, { name: 'parseTreeSitter' });
-    return Array.isArray(result) ? result : null;
+    if (Array.isArray(result) && result.length) return result;
+
+    // Null/empty results from a worker are treated as a failure signal; retry in-thread for determinism.
+    return buildTreeSitterChunks({ text, languageId, ext, options: fallbackOptions });
   } catch (err) {
     if (options?.log && !treeSitterState.loggedWorkerFailures.has('run')) {
       options.log(`[tree-sitter] Worker parse failed; falling back to main thread (${err?.message || err}).`);
       treeSitterState.loggedWorkerFailures.add('run');
     }
-    return buildTreeSitterChunks({ text, languageId, ext, options });
+    return buildTreeSitterChunks({ text, languageId, ext, options: fallbackOptions });
   } finally {
     if (shouldRecordMetrics) {
       const durationMs = Date.now() - metricsStart;
diff --git a/src/lang/tree-sitter/options.js b/src/lang/tree-sitter/options.js
index ac21d5a..a45b726 100644
--- a/src/lang/tree-sitter/options.js
+++ b/src/lang/tree-sitter/options.js
@@ -2,7 +2,19 @@ import { TREE_SITTER_LANGUAGE_IDS } from './config.js';
 
 function normalizeEnabled(value) {
   if (value === false) return false;
-  if (value === 'off') return false;
+  if (value === true) return true;
+
+  if (typeof value === 'number') {
+    if (value === 0) return false;
+    if (value === 1) return true;
+  }
+
+  if (typeof value === 'string') {
+    const v = value.trim().toLowerCase();
+    if (v === 'off' || v === 'false' || v === '0' || v === 'no') return false;
+    if (v === 'on' || v === 'true' || v === '1' || v === 'yes') return true;
+  }
+
   return true;
 }
 
diff --git a/src/lang/tree-sitter/runtime.js b/src/lang/tree-sitter/runtime.js
index 7dd6f8b..d26376f 100644
--- a/src/lang/tree-sitter/runtime.js
+++ b/src/lang/tree-sitter/runtime.js
@@ -245,8 +245,19 @@ export function getTreeSitterParser(languageId, options = {}) {
     if (!treeSitterState.sharedParser) {
       treeSitterState.sharedParser = new treeSitterState.TreeSitter();
       treeSitterState.sharedParserLanguageId = null;
-      // Clear the legacy per-language cache to avoid keeping extra Parsers alive.
-      treeSitterState.parserCache?.clear?.();
+      // Clear and dispose the legacy per-language cache to avoid keeping extra Parsers alive.
+      if (treeSitterState.parserCache && typeof treeSitterState.parserCache.values === 'function') {
+        for (const cached of treeSitterState.parserCache.values()) {
+          if (cached && typeof cached.delete === 'function') {
+            try {
+              cached.delete();
+            } catch {
+              // ignore
+            }
+          }
+        }
+        treeSitterState.parserCache.clear();
+      }
     }
 
     if (treeSitterState.sharedParserLanguageId !== resolvedId) {
diff --git a/src/lang/tree-sitter/worker.js b/src/lang/tree-sitter/worker.js
index bcafe9a..ebee06a 100644
--- a/src/lang/tree-sitter/worker.js
+++ b/src/lang/tree-sitter/worker.js
@@ -36,6 +36,9 @@ export const sanitizeTreeSitterOptions = (treeSitter) => {
     maxBytes: config.maxBytes ?? null,
     maxLines: config.maxLines ?? null,
     maxParseMs: config.maxParseMs ?? null,
+    maxAstNodes: config.maxAstNodes ?? null,
+    maxAstStack: config.maxAstStack ?? null,
+    maxChunkNodes: config.maxChunkNodes ?? null,
     byLanguage: config.byLanguage || {},
     configChunking: config.configChunking === true
   };
diff --git a/src/lang/workers/tree-sitter-worker.js b/src/lang/workers/tree-sitter-worker.js
index 0382cc4..e67679e 100644
--- a/src/lang/workers/tree-sitter-worker.js
+++ b/src/lang/workers/tree-sitter-worker.js
@@ -1,7 +1,81 @@
-import { buildTreeSitterChunks } from '../tree-sitter.js';
+import { buildTreeSitterChunks, preloadTreeSitterLanguages } from '../tree-sitter.js';
 
-export function parseTreeSitter(payload = {}) {
+function normalizeEnabled(value) {
+  if (value === false) return false;
+  if (value === true) return true;
+
+  if (typeof value === 'number') {
+    if (value === 0) return false;
+    if (value === 1) return true;
+  }
+
+  if (typeof value === 'string') {
+    const v = value.trim().toLowerCase();
+    if (v === 'off' || v === 'false' || v === '0' || v === 'no') return false;
+    if (v === 'on' || v === 'true' || v === '1' || v === 'yes') return true;
+  }
+
+  return true;
+}
+
+function isLanguageEnabled(treeSitterConfig, languageId) {
+  const config = treeSitterConfig && typeof treeSitterConfig === 'object' ? treeSitterConfig : {};
+  const enabled = normalizeEnabled(config.enabled);
+  if (!enabled) return false;
+
+  const langs = config.languages || {};
+  if (languageId && Object.prototype.hasOwnProperty.call(langs, languageId)) {
+    return normalizeEnabled(langs[languageId]);
+  }
+  if ((languageId === 'cpp' || languageId === 'objc')
+    && Object.prototype.hasOwnProperty.call(langs, 'clike')) {
+    return normalizeEnabled(langs.clike);
+  }
+  return true;
+}
+
+function resolveLanguageForExt(languageId, ext) {
+  const normalizedExt = typeof ext === 'string' ? ext.toLowerCase() : '';
+  if (normalizedExt === '.tsx') return 'tsx';
+  if (normalizedExt === '.jsx') return 'jsx';
+  if (normalizedExt === '.ts' || normalizedExt === '.cts' || normalizedExt === '.mts') return 'typescript';
+  if (normalizedExt === '.js' || normalizedExt === '.mjs' || normalizedExt === '.cjs' || normalizedExt === '.jsm') {
+    return 'javascript';
+  }
+  if (normalizedExt === '.py') return 'python';
+  if (normalizedExt === '.json') return 'json';
+  if (normalizedExt === '.yaml' || normalizedExt === '.yml') return 'yaml';
+  if (normalizedExt === '.toml') return 'toml';
+  if (normalizedExt === '.md' || normalizedExt === '.mdx') return 'markdown';
+  if (languageId) return languageId;
+  if (!normalizedExt) return null;
+  if (normalizedExt === '.m' || normalizedExt === '.mm') return 'objc';
+  if (normalizedExt === '.cpp' || normalizedExt === '.cc' || normalizedExt === '.cxx'
+    || normalizedExt === '.hpp' || normalizedExt === '.hh' || normalizedExt === '.hxx') return 'cpp';
+  if (normalizedExt === '.c' || normalizedExt === '.h') return 'clike';
+  return null;
+}
+
+/**
+ * Piscina worker entrypoint.
+ *
+ * Note: Worker threads do not share the main thread's module state.
+ * We must initialize web-tree-sitter and load the grammar inside the worker
+ * before running any parses, otherwise every parse returns null.
+ */
+export async function parseTreeSitter(payload = {}) {
   const { text = '', languageId = null, ext = null, treeSitter = null } = payload;
+
+  try {
+    const resolvedId = resolveLanguageForExt(languageId, ext);
+    if (resolvedId && isLanguageEnabled(treeSitter, resolvedId)) {
+      // Cached by the runtime module within this worker thread.
+      await preloadTreeSitterLanguages([resolvedId]);
+    }
+  } catch {
+    // If init/preload fails in this worker, fall back to heuristic chunking upstream.
+  }
+
   try {
     return buildTreeSitterChunks({
       text,
