# Completed Phases 

Any time a phase is fully completed, AFTER it has been merged into main:
  - The numbering and ordering of phases does not matter whatsoever
  - Remove the phase from the current roadmap
  - Append the Title and a brief, single item summary 
  - Some phase numbers are reused 
  - Nothing in this document should be treated as authoritative, refer to code for truth

Completed phase snapshots are archived here after being removed from GIGAROADMAP.md. 

---

- Phase R -- Make Monoliths Modular, My Man

## Phase R -- Refactor MegaCut 

---

### R.0 Refactor playbook (applies to every subtask)

**Goal:** Split “fat” modules into cohesive, testable, side-effect-minimized modules **without changing behavior**.

**Hard rules**
- **No behavior changes** unless explicitly called out in the task’s “Behavior deltas” section.
- **Preserve public entrypoints.** If you move code, keep a tiny compatibility shim at the old path that re-exports the same names.
- **Keep ESM import style** (repo is `"type": "module"`; keep `.js` extensions on relative imports).
- **No new global state**; prefer pure helpers and dependency injection (pass `log`, `signal`, configs, caches).
- **Avoid circular imports** by extracting shared primitives to `src/shared/**` and keeping “leaf” modules free of imports from high-level orchestrators.

**PR checklist**
- [x] New modules have a single responsibility and minimal export surface.
- [x] All call sites updated (or compatibility re-export added).
- [x] All relevant tests pass:
  - `node tests/run.js --lane pr` (preferred) or `npm run test:pr`
  - plus any targeted tests called out per task.
- [x] `npm run lint` passes.
- [x] File sizes: prefer < ~500 LOC for “leaf” modules; orchestrators may be larger but should be mostly glue.

---

### R.1 Script surface policy + docs (package.json sprawl)

**Spec conflict (resolved):** The original Phase R.1 demanded `package.json` scripts be reduced to <10.  
The current repo has already adopted a **policy-based approach** instead:
- `tools/script-inventory.js` generates `docs/tooling/script-inventory.json` and `docs/guides/commands.md`.
- `tests/policy/script-surface-policy.test.js` enforces that the inventory matches `package.json`.

This is a better trade-off than “<10 scripts” because:
- Many scripts are intentionally “debuggable entrypoints” for specific tests/tools.
- The repo has explicit policy + inventory tooling already; rewriting the entire script surface would be noisy and high-churn.

#### R.1.1 Script inventory + policy enforcement
- [x] Keep `tools/script-inventory.js` as the single generator for:
  - `docs/tooling/script-inventory.json`
  - `docs/guides/commands.md`
- [x] Keep `tests/policy/script-surface-policy.test.js` enforcing inventory ↔ package parity.

**Callouts**
- Generator: `tools/script-inventory.js`
- Inventory: `docs/tooling/script-inventory.json`
- Policy test: `tests/policy/script-surface-policy.test.js`

#### R.1.2 Fix doc drift: commands.md must be reproducible
- [x] Resolve the current mismatch where `docs/guides/commands.md` contains a “Phase 3 specs” section that **is not emitted** by `tools/script-inventory.js`.
  - **Best choice:** make `commands.md` purely generated; either:
    1) Update generator to also emit a “Phase specs” section (recommended), or  
    2) Remove the non-generated section from `commands.md` and move it to a separate doc (less ideal; increases doc surface).
- [x] Add a policy test to prevent future drift:
  - New test file: `tests/policy/script-inventory-docs.test.js`
  - It should run the generator in-memory and compare against `docs/guides/commands.md` OR at minimum assert:
    - the “generated by” header is present
    - the “Stable entrypoints” block matches the generator’s output
    - the script table contains the same script names as inventory

**Why option (1) is recommended:**  
The repo already treats `commands.md` as generated. Making the generator responsible for *all* its sections is the only way to keep it deterministic and enforceable.

#### R.1.3 Tighten the “stable entrypoints” contract
- [x] Document (and keep stable) the following script entrypoints:
  - `test`, `test:pr`, `test:nightly`, `lint`, `format`, `config:budget`, `env:check`, `verify`
- [x] Update any user-facing docs / error messages that reference non-stable scripts to prefer:
  - `pairofcleats ...` CLI entrypoints (preferred for users)
  - or `node <script>` for internal tools
- [x] Add a lightweight test that fails if “stable entrypoints” are removed/renamed without updating docs/tooling/script-inventory.json.

---

### R.2 Repo hygiene + drift-proofing

#### R.2.1 AGENTS.md coverage
- [x] Ensure `AGENTS.md` lists the primary docs to read and how to run tests/lint.
- [x] Add an explicit pointer to the script policy docs:
  - `docs/tooling/script-inventory.json`
  - `docs/guides/commands.md`
  - The enforcement test: `tests/policy/script-surface-policy.test.js`

#### R.2.2 Drift-proofing for docs ↔ code contracts
- [x] Keep the existing “policy tests” approach (see `tests/policy/**`) for anything that otherwise drifts silently.

#### R.2.3 Optional: sweep stale files (low-risk cleanup)
- [x] Add a non-destructive report script (no deletions) that inventories:
  - orphan docs (not referenced by any “Docs to read” list)
  - orphan tools (not referenced by any script/CLI)
  - orphan scripts (not referenced by docs/CI/tests)
- Suggested location: `tools/repo-inventory.js`
- Output: `docs/tooling/repo-inventory.json`
- [x] Add a policy test that only checks the file exists + JSON schema sanity (don’t gate PRs on the contents yet).

---

### R.3 Shared primitives (extract early, reuse everywhere)

These have landed and should be used as the canonical helpers.

#### R.3.1 Backoff/retry helper
- [x] `src/shared/retry.js` exports `retryWithBackoff({ attempts, minDelayMs, maxDelayMs, factor, jitter, shouldRetry, operation, signal })`
- [x] Used by `src/index/build/watch/lock.js` to implement `acquireIndexLockWithBackoff(...)`.
- Tests (existing): `tests/watch-lock-backoff.js`

**Follow-up**
- [x] Add a small direct unit test for `retryWithBackoff` itself (optional but improves locality):
  - New: `tests/retry-with-backoff.js`
  - Cover: abort signal, shouldRetry false, jitter bounds, attempts=1 behavior.

#### R.3.2 Debounce scheduler
- [x] `src/shared/scheduler/debounce.js` exports `createDebouncedScheduler({ delayMs, maxDelayMs, onFlush })`
- [x] Used by watch pipeline (via `src/index/build/watch.js`).
- Tests (existing): `tests/watch-debounce.js`

#### R.3.3 Ignore matcher helper (path + chokidar semantics)
- [x] `src/shared/fs/ignore.js` exports `buildIgnoredMatcher({ root, ignoreMatcher })` for chokidar-compatible ignores.
- [x] Add a dedicated test for “directory ignore vs file ignore” semantics:
  - New: `tests/ignore-matcher.js`
  - Cases:
    - ignoreMatcher matches a directory: should ignore descendants (simulate `stats.isDirectory()` true)
    - ignoreMatcher matches a file path: should ignore only that path
    - Windows path normalization (`\` → `/`) must not break matching
  - Import the helper directly from `src/shared/fs/ignore.js`.

#### R.3.4 Filter list merge helper
- [x] `src/shared/filter/merge.js` exports `mergeFilterLists(a, b)`
- [x] Used by `src/retrieval/filters.js` (`mergeExtFilters`, `mergeLangFilters`) and tested via:
  - `tests/lang-filter.js`

---

### R.4 Core indexing + build pipeline refactors

#### R.4.1 Watch pipeline split
- [x] `src/index/build/watch.js` is now an orchestrator that delegates to:
  - `src/index/build/watch/args.js` (args normalization)
  - `src/index/build/watch/chokidar-backend.js` / `polling-backend.js`
  - `src/index/build/watch/watch-event-queue.js`
  - `src/index/build/watch/stability.js` (stability guard)
  - `src/index/build/watch/lock.js` (index lock + backoff)
  - `src/index/build/watch/rebuild.js` (rebuild trigger)
- Tests (existing):
  - `tests/watch-backend-selection.js`
  - `tests/watch-debounce.js`
  - `tests/watch-lock-backoff.js`
  - `tests/watch-stability-guard.js`
  - (plus several watch E2E/atomicity tests)

**Remaining (optional)**
- [x] If `watch.js` grows again, prefer extracting additional “pure helpers” to `src/index/build/watch/*.js` rather than re-introducing large inline blocks. Note this in the docs for watch/build

#### R.4.2 Integrations/core split (spec drift fix)

**Spec drift:** The old roadmap targeted `src/integrations/core/index.js` as a 700+ LOC monolith.  
In the current codebase, `src/integrations/core/index.js` is a tiny re-export facade, and the largest module is now:

- **Current monolith target:** `src/integrations/core/build-index.js` (~735 LOC)

##### R.4.2.1 Keep the facade pattern
- [x] `src/integrations/core/index.js` should remain a small re-export surface for:
  - `buildIndex`, `buildSqliteIndex` (from `build-index.js`)
  - `search` (from `search.js`)
  - `status` (from `status.js`)
- [x] Other integration helpers already live in `src/integrations/core/*.js`

##### R.4.2.2 Split build-index integration logic
- [x] Refactor `src/integrations/core/build-index.js` into a folder:
  - `src/integrations/core/build-index/index.js` (orchestrator; exports `buildIndex`, `buildSqliteIndex`)
  - `src/integrations/core/build-index/progress.js` (overall progress aggregation; current inline “overallProgress” logic)
  - `src/integrations/core/build-index/compatibility.js` (compat key computation)
  - `src/integrations/core/build-index/runtime.js` (runtime bootstrap/teardown helpers)
  - `src/integrations/core/build-index/stages.js` (stage1/stage2 planning + dispatch)
  - `src/integrations/core/build-index/sqlite.js` (the `buildSqliteIndex` implementation)

**Compatibility requirements**
- Keep exports stable from `src/integrations/core/index.js`.
- Keep the existing `buildIndex(repoRoot, options)` and `buildSqliteIndex(repoRoot, options)` signatures intact.

**Callers**
- `bin/pairofcleats.js` (via integration layer)
- `tools/mcp/tools.js` uses `coreBuildIndex` / `coreBuildSqliteIndex`
- Tests that invoke `build_index.js` script (various E2E tests)

**Tests to run**
- `node tests/run.js --match build-index --match index-lock --match watch-atomicity` (minimum)
- `node tests/run.js --lane pr` (recommended)

#### R.4.3 Runtime refactor
- [x] Runtime has been split into:
  - `src/index/build/runtime/config.js`, `policy.js`, `stage.js`, `workers.js`, `hash.js`, etc.
- [x] `src/index/build/runtime/runtime.js` remains large (~680 LOC) but is primarily orchestrator + normalization.

**Optional follow-up**
- [x] Extract “option normalization” helpers from `runtime.js` into `runtime/normalize.js` if `runtime.js` continues to grow.
- [x] Add a unit test for “caps/policy merges” if regressions occu.

#### R.4.4 Validate split
- [x] `src/index/validate.js` delegates to `src/index/validate/*` modules (`manifest`, `sqlite`, `lmdb`, etc.)
- Tests (existing): search for `validate` lane/scripts in `tests/script-coverage` actions.

#### R.4.5 Artifacts build split
- [x] `src/index/build/artifacts.js` delegates into `src/index/build/artifacts/*` (filter-index, postings, bundles, etc.)
- Ensure any new artifact type also updates:
  - `docs/contracts/artifact-contract.md`
  - `src/contracts/schemas/artifacts.js` (if schema is used)
  - relevant validation in `src/index/validate/*`

#### R.4.6 Worker pool split
- [x] Worker pool logic is now under `src/index/build/workers/*`
- `src/index/build/worker-pool.js` is a facade.

#### R.4.7 File processor split (CPU + chunk processing)

**Current state**
- [x] `src/index/build/file-processor/cpu.js` is ~586 LOC and already delegates chunking to:
  - `src/index/build/file-processor/cpu/chunking.js`
- **New monolith candidate:** `src/index/build/file-processor/process-chunks.js` (~650 LOC)

**Plan**
- [x] Keep `cpu.js` as the “single-file CPU orchestration” entrypoint (export `processFileCpu(...)`), but extract:
  - tokenization setup / caching → `cpu/tokenizer.js`
  - AST/tree-sitter analysis pass wrappers → `cpu/analyze.js`
  - metadata v2 enrichment steps → `cpu/meta.js`
  - keep `cpu/chunking.js` as-is

- [x] Split `process-chunks.js` into:
  - `file-processor/process-chunks/index.js` (orchestrator)
  - `file-processor/process-chunks/enrichment.js` (enrich + merge docmeta)
  - `file-processor/process-chunks/dedupe.js` (dedupe + normalization)
  - `file-processor/process-chunks/limits.js` (chunk limits + truncation policy)
  - `file-processor/process-chunks/ids.js` (chunk id assignment + stability rules)

**Callers**
- `src/index/build/indexer/steps/process-files.js`
- any tests building indexes (`tests/e2e-smoke.js`, etc.)

**Tests to run**
- `node tests/run.js --match segment-pipeline --match chunking-limits --match metadata-v2`
- plus at least one full index build smoke (`tests/e2e-smoke.js` or `tests/build-index-all.js` if present)

#### R.4.8 Piece assembly split
- [x] `src/index/build/piece-assembly.js` is still ~500 LOC; helpers exist at `src/index/build/piece-assembly/helpers.js`.

**Remaining extraction (recommended)**
- [x] Extract the IO-heavy loader to `src/index/build/piece-assembly/load.js`
  - Move `loadIndexArtifacts(...)` and any “find pieces / read manifest / read artifacts” logic.
- [x] Extract merge logic to `src/index/build/piece-assembly/merge.js`
  - “merge postings / merge bundles / merge filter index / merge relations” helpers
- [x] Keep `assembleIndexPieces(...)` in `piece-assembly.js` as orchestrator (or move to `piece-assembly/index.js` with a facade).

**Callers**
- `tools/assemble-pieces.js` (CLI tool)
- `tests/contracts/index-compatibility-key-federation-block.test.js`

**Tests to run**
- `node tests/run.js --match compact-pieces --match index-compatibility-key-federation-block`

---

### R.5 Retrieval refactors

#### R.5.1 `filterChunks` split (`src/retrieval/output/filters.js`)

**Current state**
- [x] `src/retrieval/output/filters.js` now delegates to `src/retrieval/output/filters/*` helpers; `filterChunks` remains the orchestrator.
- [x] Candidate selection helpers already extracted:
  - `src/retrieval/output/filters/candidates.js` exports `createCandidateHelpers(...)`
- The file implements:
  - meta filters (`meta.*`, risk fields, etc.)
  - structural filters (`structPack`, `structRule`, `structTag`)
  - file/path/ext/lang prefiltering using `filterIndex` chargrams + roaring bitmaps
  - relation filters (`uses`, `imports`, `calls`) via `fileRelations`

**Specs to follow**
- File prefilter semantics: `docs/guides/search.md` (“File Filter Prefilter (Substring/Regex)”)
- Search filter contract: `docs/contracts/search-contract.md` + `docs/contracts/search-cli.md`
- Structural filter doc: `docs/guides/structural-search.md`

**Public entrypoint**
- Keep: `export function filterChunks(meta, filters = {}, filterIndex = null, fileRelations = null)`

**Callers**
- `src/retrieval/output.js` re-exports it
- `src/retrieval/pipeline.js` calls it
- Many tests import from `src/retrieval/output.js`

**Refactor plan (safe + incremental)**
- [x] **Step 1: fix formatting drift** in `filters.js` (indentation currently broken in destructuring blocks).
- [x] **Step 2: extract pure predicates** to `src/retrieval/output/filters/predicates.js`
  - `matchList`, `matchAny`, `truthy`, and any “normalize list” helpers.
- [x] **Step 3: extract structural matching** to `src/retrieval/output/filters/structural.js`
  - `matchStructural(chunk, { structPack, structRule, structTag })`
  - Must match semantics verified by `tests/structural-filters.js`.
- [x] **Step 4: extract meta matching** to `src/retrieval/output/filters/meta.js`
  - `matchMetaFilters(chunk, metaFilters, riskFilters, options)`
  - Preserve support for:
    - `meta` (k/v string or regex) and `caseMeta`
    - risk selectors: `risk`, `riskTag`, `riskCategory`, `riskSource`, `riskSink`, `riskFlow`
    - inferred types: `inferredType`, `returnType`, `param`
- [x] **Step 5: extract file/path filter evaluation** to `src/retrieval/output/filters/file.js`
  - Build final exact predicate for:
    - `file`/`caseFile` (substring or regex; supports list)
    - `ext`, `lang`
  - Keep **final exact match** always enforced even when prefilter narrows candidates.
- [x] **Step 6: extract file prefilter (chargram/roaring)** to `src/retrieval/output/filters/file-prefilter.js`
  - `collectFilePrefilterMatches({ filterIndex, fileMatchers, caseFile, fileChargramN, roaring })`
  - Must implement doc semantics:
    - longest stable literal from regex; skip if none
    - case-insensitive prefilter; exact match still checks case when `caseFile` is true
- [x] **Step 7: keep filterChunks orchestrator** in `filters.js` (or move to `filters/index.js` and re-export from `filters.js`)
  - It should:
    - normalize filters once
    - construct candidate sets using `createCandidateHelpers`
    - loop candidates and apply exact predicates
    - handle `fileRelations` expansion for `uses/imports/calls` filters

**Tests to run (existing, must pass unchanged)**
- `tests/filter-index.js`
- `tests/filter-strictness.js`
- `tests/filter-structural.js` / `tests/structural-filters.js`
- `tests/file-case-sensitive.js`
- `tests/filters-file.js`
- `tests/lang-filter.js`

*(Search for additional filter tests in `/tests` prefixed with `filter-` and run them too.)*

#### R.5.2 Search CLI split (`src/retrieval/cli.js`)
- [x] `runSearchCli(...)` now delegates inline helpers and run-config normalization to `src/retrieval/cli/*`; `cli.js` is orchestration glue.

**Refactor goal**
- Keep `runSearchCli(...)` export stable (callers: `src/integrations/core/search.js`).
- Reduce `cli.js` to “parse → normalize → run session → render/persist” glue.

**Plan**
- [x] Extract inline helpers inside `runSearchCli` to `src/retrieval/cli/runner.js`:
  - `inferJsonOutputFromArgs`
  - `emitError` / `bail`
  - `throwIfAborted`
- [x] Extract the giant `normalized` destructuring + derived flags into:
  - `src/retrieval/cli/resolve-run-config.js`
  - Return a single `runConfig` object (typed by convention / JSDoc) consumed by `runSearchSession`.
- [x] Keep `src/retrieval/cli.js` as the orchestrator that wires modules together.

**Tests to run**
- `node tests/run.js --match search-cli --match sqlite-fts-eligibility --match search-symbol-boost`

#### R.5.3 Language registry split
- [x] `src/index/language-registry/registry.js` is now small; data lives in `registry-data.js`.
- Ensure any future registry edits update:
  - `src/index/language-registry/registry-data.js`
  - tests that validate language ids / aliases (search for `language-registry` in tests)

#### R.5.4 Search pipeline split (`src/retrieval/pipeline.js`)

**Current state**
- [x] `src/retrieval/pipeline.js` now delegates query-AST, ANN backend normalization, and fusion helpers to `src/retrieval/pipeline/*`.
- `src/retrieval/pipeline.js` still mixes:
  - query-AST phrase checks
  - backend selection (ANN, sqlite FTS, etc.)
  - scoring logic (RRF, blend, symbol boosts, phrase boosts)
  - context-expansion

**Specs to follow**
- `docs/contracts/search-contract.md`
- `docs/guides/search.md`
- `docs/contracts/search-cli.md`

**Public entrypoint**
- Keep: `export function createSearchPipeline(context = {})`

**Callers**
- `src/retrieval/cli/run-search-session.js`
- tests: `tests/search-symbol-boost.js`, `tests/retrieval/sqlite-fts-eligibility.js`, and others

**Refactor plan**
- [x] Extract query-AST helpers to `src/retrieval/pipeline/query-ast.js`
  - move `matchesQueryAst(...)`
  - move `getPhraseMatchInfo(...)`
  - keep the exact signatures to avoid churn
- [x] Extract ANN backend normalization to `src/retrieval/pipeline/ann-backends.js`
  - move `normalizeAnnBackend(...)`, `resolveAnnOrder(...)`
- [x] Extract score fusion to `src/retrieval/pipeline/fusion.js`
  - a pure function that takes ranked sparse list, ranked dense list, config → fused list + breakdowns
  - keep existing behavior: default RRF, optional normalized blending via `search.scoreBlend.*`
- [x] Keep `pipeline.js` as orchestrator:
  - loads providers (BM25, sqlite fts, ann, minhash)
  - delegates to extracted helpers
  - keeps `createSearchPipeline` signature stable

**Tests to run**
- `tests/search-symbol-boost.js`
- `tests/retrieval/sqlite-fts-eligibility.js`
- `tests/search-rrf-parity.js` (if present)
- `tests/search-explain-schema.js` (if present)
- plus `node tests/run.js --lane pr`

#### R.5.5 JSON stream split
- [x] `src/shared/json-stream.js` is a facade over `src/shared/json-stream/*`

#### R.5.6 Filter merge module
- [x] `src/retrieval/filters.js` uses `src/shared/filter/merge.js`

---

### R.6 Tooling & services refactors

#### R.6.1 MCP tool dispatcher split (`tools/mcp/tools.js`)

**Current state**
- [x] `tools/mcp/tools.js` now delegates to `tools/mcp/tools/handlers/*` with a handler map.
- Helpers already extracted to: `tools/mcp/tools/helpers.js`

**Specs to follow**
- Tool defs + schemas are the source of truth:
  - `src/integrations/mcp/defs.js`
- Tests that enforce handler coverage:
  - `tests/mcp/tools-registry.test.js`
  - `tests/mcp/tools-normalize-meta.test.js`

**Public entrypoints (must remain exported)**
- `buildIndex`
- `runSearch`
- `downloadModels`, `downloadDictionaries`, `downloadExtensions`, `verifyExtensions`
- `buildSqliteIndex`, `compactSqliteIndex`
- `cacheGc`, `cleanArtifacts`, `runBootstrap`, `reportArtifacts`
- `triageIngest`, `triageDecision`, `triageContextPack`
- `handleToolCall`
- `normalizeMetaFilters` (re-export)

**Refactor plan**
- [x] Create folder: `tools/mcp/tools/handlers/`
  - `index-status.js` → `indexStatus`, `configStatus` (or keep in `tools/mcp/repo.js` if already there)
  - `indexing.js` → `buildIndex`, `buildSqliteIndex`, `compactSqliteIndex`
  - `search.js` → `runSearch`
  - `downloads.js` → `downloadModels`, `downloadDictionaries`, `downloadExtensions`, `verifyExtensions`
  - `artifacts.js` → `cleanArtifacts`, `reportArtifacts`, `cacheGc`
  - `bootstrap.js` → `runBootstrap`
  - `triage.js` → `triageIngest`, `triageDecision`, `triageContextPack`
- [x] Replace the `handleToolCall` switch with a map:
  - `const TOOL_HANDLERS = new Map([ ['search', runSearch], ... ])`
  - `handleToolCall(name, args, ctx)` looks up handler and throws unknown tool error if missing.
- [x] Update `tests/mcp/tools-registry.test.js` accordingly:
  - Instead of parsing switch cases, assert:
    - every tool name in `getToolDefs({ ... })` has a handler in the map
    - no extra handlers exist for undefined tools

**Compatibility requirements**
- Preserve handler behavior (progress callbacks, env resolution, JSON parsing errors).
- Keep error messages stable enough for tests (if tests assert substrings, keep them).

#### R.6.2 API router split
- [x] `tools/api/router.js` already delegates to `tools/api/router/*`

#### R.6.3 build-embeddings split
- [x] `tools/build-embeddings/run.js` delegates to `tools/build-embeddings/*`

#### R.6.4 build-sqlite-index split
- [x] `tools/build-sqlite-index/run.js` delegates to `tools/build-sqlite-index/*`

#### R.6.5 config-inventory split
- [x] `tools/config-inventory.js` delegates to `tools/config-inventory/*`

#### R.6.6 dict-utils split
- [x] `tools/dict-utils.js` is the public facade; internal helpers live in `tools/dict-utils/*`

---

### R.7 UI refactors

#### R.7.1 Map isometric edge assembly split (`src/map/isometric/client/edges.js`)

**Current state**
- [x] `edges.js` now delegates to `edges/aggregate.js`, `edges/endpoints.js`, `edges/style.js` plus existing helpers.
  - `src/map/isometric/client/edges/resolvers.js` (`createEdgeResolvers`)
  - `src/map/isometric/client/edges/routing.js` (`createRoutingHelpers`)
- Remaining in `edges.js`: aggregation + rendering shape logic.

**Public entrypoint**
- Keep: `export function buildEdges({...})`

**Refactor plan**
- [x] Extract edge aggregation to `src/map/isometric/client/edges/aggregate.js`
  - logic that builds per-edge segments + dedupes
- [x] Extract “endpoint dots” to `src/map/isometric/client/edges/endpoints.js`
- [x] Extract styling/resolution to `src/map/isometric/client/edges/style.js`
  - color/opacity decisions based on selection, hover, depth, etc.
- [x] Keep `edges.js` as orchestrator that wires:
  - resolvers + routing + aggregation + endpoints + style

**Tests (missing today)**
- [x] Add a small unit test suite under `tests/map/edges.test.js`:
  - route helper produces deterministic paths given fixed nodes
  - edge resolver consistently assigns inbound/outbound per node orientation
  - aggregation is stable (same input → same output ordering)

---

### R.8 Post-refactor follow-ups

- [x] Update `docs/guides/architecture.md` if module boundaries materially change (filters/pipeline/tools).
- [x] Update `docs/guides/commands.md` and `docs/tooling/script-inventory.json` if any script entrypoints changed.

---

### R.9 Current monolith snapshot (2026-01-30)

Top refactor candidates by size/complexity (non-generated, behavior-heavy):
1. `src/integrations/core/build-index.js` (~735 LOC) → split per **R.4.2.2**
2. `src/retrieval/cli.js` (~719 LOC) → reduce glue per **R.5.2**
3. `src/index/build/watch.js` (~703 LOC, but already modular) → optional further extraction
4. `src/index/build/runtime/runtime.js` (~683 LOC, mostly orchestrator) → optional normalize split
5. `src/index/build/file-processor/process-chunks.js` (~650 LOC) → split per **R.4.7**
6. `tools/mcp/tools.js` (~650 LOC) → split per **R.6.1**
7. `src/retrieval/pipeline.js` (~638 LOC) → split per **R.5.4**
8. `src/retrieval/output/filters.js` (~570 LOC) → split per **R.5.1**
9. `src/index/build/piece-assembly.js` (~500 LOC) → split per **R.4.8**
10. `src/map/isometric/client/edges.js` (~500 LOC) → split per **R.7.1**

---


## Phase 6 -- Finalization

> **Important:** A meaningful portion of this phase may already be implemented in this repo.  
> Before writing new code, **audit the referenced files/tests** and only add/modify what’s missing or incorrect.

### Goals

1. **Determinism & portability:** VFS virtual paths and “call_sites” output must be stable across runs/OSes.
2. **Artifact correctness:** VFS manifest and metaV2 must be correct, schema-valid, and consistent with post-processing.
3. **Noise reduction:** Improve call/usage heuristics and tokenization so keyword noise is controlled without losing queryability.
4. **CI completeness:** CI lanes must always run schema/validator coverage; long tests must be runnable in a dedicated lane.

---

## 6.0 Audit checklist (do this first)

- [x] Confirm these Phase 6 tests already exist and are green:
  - `tests/vfs/virtual-path-stability.test.js`
  - `tests/vfs/vfs-manifest-roundtrip.test.js`
  - `tests/indexer/call-sites-determinism.test.js`
  - `tests/indexer/metav2-recompute-equivalence.test.js`
- [x] Confirm VFS manifest is actually produced during an index build:
  - Collection: `src/index/build/file-processor/process-chunks.js` → `buildVfsManifestRowsForFile()`
  - State aggregation: `src/index/build/indexer/steps/process-files.js` → `state.vfsManifestRows`
  - Emission: `src/index/build/artifacts/writers/vfs-manifest.js` → `enqueueVfsManifestArtifacts()`
  - Manifest wiring: `src/index/build/artifacts.js` adds piece `vfs_manifest`
- [x] Confirm metaV2 finalization happens *after* any mutation steps:
  - Cross-file inference: `src/index/build/indexer/steps/relations.js` → `runCrossFileInference()` mutates `chunk.docmeta` / `chunk.codeRelations`
  - Finalization: `src/index/build/indexer/steps/write.js` → `finalizeMetaV2({ chunks })` **before** writing artifacts
- [x] Confirm GitHub Actions PR CI runs `ci-lite` (and thus includes contracts + validate coverage):
  - Workflow: `.github/workflows/ci.yml`
  - Test command: `npm run test:ci-lite`
  - Source of truth list: `tests/ci-lite/ci-lite.order.txt`

If any item above is missing, fix it as part of Phase 6 (details below).

---

## 6.1 VFS hardening: stable virtual paths + manifest roundtrip

### 6.1.1 VFS Virtual Path specification (source of truth)

**Primary implementation:** `src/index/tooling/vfs.js`

- `VFS_PREFIX` is `".poc-vfs"`.
- `buildVfsVirtualPath({ containerPath, segmentUid, ext, effectiveExt })` must be:
  - **Pure & deterministic** (same inputs → same output across runs/OS).
  - **Path-safe for LSP/tooling** (no OS separators except `/`).
  - **Stable across host paths**: uses `normalizeRelPath()` and `encodeContainerPath()`:
    - `encodeContainerPath()` base64url-encodes the normalized relative path.
    - `decodeContainerPath()` reverses it.
  - **Segment addressing is explicit**:
    - If `segmentUid` is present: suffix is `"#seg:<segmentUid>"`.
    - Otherwise, no segment suffix.
  - **Extension selection rules**:
    - `effectiveExt` (if non-empty) takes precedence over `ext`.
    - Both are normalized to include a leading dot when present.
    - If neither exists, no extension suffix is added.

**Disk path mapping for tooling (not “virtual path”):**
- `resolveVfsDiskPath({ baseDir, virtualPath })`:
  - Splits the virtual path on `/` into components.
  - Encodes Windows-illegal characters in each component via `encodeURIComponent()` for `[:*?"<>|]`.
  - Joins using `path.sep` and roots at `baseDir`.

The **stable spec** is: *virtual paths are posix-style with `/`, disk paths are OS-safe via escaping.*

---

### 6.1.2 Task: Virtual path stability test

**Test file (must exist and pass):** `tests/vfs/virtual-path-stability.test.js`

**Must validate:**
- [x] Determinism: multiple invocations with identical inputs are string-equal.
- [x] Segment switching: changing `segmentUid` changes output only in the `#seg:` suffix.
- [x] Effective extension: `effectiveExt` overrides `ext`.
- [x] Cross-platform invariants:
  - The returned string always starts with `".poc-vfs/"`.
  - It never contains `\` (backslash), even on Windows.
  - It does not include raw absolute paths.

**Key implementation references:**
- `src/index/tooling/vfs.js`:
  - `buildVfsVirtualPath()`
  - `encodeContainerPath()`, `decodeContainerPath()`
  - `normalizeRelPath()` (imported from `../../shared/paths.js`)

If the existing test doesn’t cover the invariants above, extend it.

---

### 6.1.3 Task: VFS manifest roundtrip test (unsharded + sharded)

**Test file (must exist and pass):** `tests/vfs/vfs-manifest-roundtrip.test.js`

**Manifest schema reference (authoritative):**
- `src/contracts/schemas/artifacts.js` → `vfsManifestRow` schema
- Manifest writer uses:
  - `src/index/build/artifacts/writers/vfs-manifest.js`
  - `VFS_MANIFEST_SCHEMA_VERSION` from `src/index/tooling/vfs.js`

**Roundtrip requirements:**
- [x] **Unsharded mode**: writing `vfs_manifest.jsonl` and reading it back returns identical rows.
- [x] **Sharded mode**: forcing shard split via `maxJsonBytes` writes:
  - `vfs_manifest.meta.json`
  - `vfs_manifest.parts/…`
  - reading back yields the same rows.
- [x] Ordering:
  - Writer sorts rows with `sortVfsManifestRows()` so output is deterministic.
- [x] Row trimming:
  - Writer enforces `MAX_ROW_BYTES` (32 KB). Oversized rows must be trimmed in a deterministic way (`maybeTrimRow()`).

**Key implementation references:**
- Writer: `src/index/build/artifacts/writers/vfs-manifest.js`
  - `createVfsManifestRows()`
  - `sortVfsManifestRows()`
  - `buildManifestRow()` / `maybeTrimRow()`
  - `enqueueVfsManifestArtifacts()`
- Reader: `src/index/tooling/vfs.js`
  - `readVfsManifestRowsFromDisk()`
  - `readVfsManifestFromIndexRoot()`

---

### 6.1.4 Task: Add a minimal VFS disk-path safety test (recommended)

**Why:** `resolveVfsDiskPath()` is used on Windows, macOS, Linux. It must not create illegal filename components.

**New test (add):**
- `tests/vfs/vfs-disk-path-safety.test.js`

**Test cases:**
- [x] A virtual path containing illegal Windows characters in a component (e.g. `":"`, `"*"`, `"?"`, `"|"`) is converted to a disk path where those characters are percent-encoded.
- [x] Returned disk path is under `baseDir` (no traversal).
- [x] `virtualPath` containing `..` as a segment is treated as a literal component (still joined under baseDir), not as traversal.
  - If you consider `..` unsafe, then explicitly encode it or reject it; document the decision and test accordingly.

**Key implementation reference:** `src/index/tooling/vfs.js` → `resolveVfsDiskPath()`.

---

## 6.2 CI coverage: schema validation + clearer CI OS lanes

### 6.2.1 Task: Ensure schema & index validation always run in PR CI

**Goal:** If artifact schemas or validators break, PR CI must fail.

**What must be covered by the PR CI lane (`ci-lite`):**
- [x] **Contract/schema tests** (minimum):
  - `tests/contracts/schema-registry-single-source.test.js`
  - `tests/contracts/public-artifact-surface-doc.test.js`
  - `tests/contracts/artifact-surface-version.test.js`
- [x] **Index validator tests** (minimum):
  - `tests/validate/index-validate-strict.test.js`
  - `tests/validate/index-validate-load-manifest.test.js`
  - `tests/validate/index-validate-missing-pieces.test.js`
  - `tests/validate/index-validate-unknown-piece.test.js`

**Source of truth for what runs in `ci-lite`:**
- `tests/ci-lite/ci-lite.order.txt`  
  CI-lite is special-cased in `tests/run.js` and uses this order file verbatim.

**Acceptance criteria:**
- The list above is present in `ci-lite.order.txt`.
- `npm run test:ci-lite` fails when you intentionally break a schema or validator check.

**Implementation references:**
- Workflow: `.github/workflows/ci.yml`
- Test runner: `tests/run.js` (ci-lite order-file logic)

---

### 6.2.2 Task: Refine GitHub Actions CI job naming and OS coverage

**Workflow file:** `.github/workflows/ci.yml`

**Problems to address:**
- Job name `test` is ambiguous (it is really **Ubuntu**).
- Windows job is named `test-windows` but uses different OS runner (`windows-2022`) than nightly (`windows-latest`).
- macOS is covered in nightly, but not PR CI.

**Required changes:**
- [x] Rename job ids + display names:
  - `test` → `ubuntu`
  - `test-windows` → `windows`
- [x] Add a `macos` job running `npm run test:ci-lite`:
  - Runner: `macos-latest`
  - Keep it blocking if it’s fast enough; otherwise make it non-blocking but visible.
- [x] Align Windows runner choice with nightly unless you have a reason:
  - Prefer `windows-latest` unless a specific toolchain requires `windows-2022`.

**Acceptance criteria:**
- PR CI UI clearly shows `ubuntu`, `windows`, and `macos`.
- All jobs run the same Node version and `npm run test:ci-lite`.

**Related workflow:** `.github/workflows/nightly.yml` (already includes macOS).

---

## 6.3 Determinism + metaV2 correctness after post-processing

### 6.3.1 Task: call_sites determinism test

**Test file (must exist and pass):** `tests/indexer/call-sites-determinism.test.js`

**What the test must guarantee:**
- [x] Two consecutive builds of the same fixture repository produce `call_sites.jsonl` output that is **line-identical**.
- [x] The fixture repo must be stable and self-contained (no network).
- [x] The test must not depend on wall-clock timestamps:
  - Compare content files, not meta `generatedAt` timestamps.

**Key implementation references:**
- Writer: `src/index/build/artifacts/writers/call-sites.js`
  - Determinism is primarily controlled by `sortCallSites(rows)`.
- Call detail production:
  - Call details are stored on `chunk.codeRelations.callDetails`.
  - Cross-file inference may add `targetChunkUid`/`targetDocId`/`targetCandidates`.

If determinism fails on Windows, inspect any path normalization differences and ensure ordering sort keys use normalized file paths (posix style `src/...`) rather than OS paths.

---

### 6.3.2 Task: Ensure metaV2 is finalized after cross-file inference mutations

**Why:** `metaV2` is a “flattened” structure derived from `chunk` + `chunk.docmeta` + `chunk.codeRelations`.  
Cross-file inference **mutates** those, so stale metaV2 would be a correctness bug.

**How it currently must work:**
- First metaV2 build (per-chunk) happens during assembly:
  - `src/index/build/file-processor/assemble.js` → `buildMetaV2(chunk)`
- Mutations happen later:
  - `src/index/build/indexer/steps/relations.js` → `runCrossFileInference()` (calls `applyCrossFileInference()`)
- Final metaV2 rebuild must happen at the end:
  - `src/index/build/indexer/steps/write.js` → `finalizeMetaV2({ chunks })`

**Acceptance criteria:**
- `finalizeMetaV2()` is invoked for every write mode (`code`, `prose`) **after** all mutation steps.
- Any artifact that includes `chunk.metaV2` is written after this finalization.

**Add/extend an integration assertion (recommended):**
- Update `tests/indexing/type-inference/crossfile-output.integration.test.js` to also assert:
  - `buildWidget.metaV2.docmeta.inferredTypes.returns` includes `{ type: "Widget", source: "flow" }`
  - `buildWidget.metaV2.codeRelations.callLinks` includes the link to `createWidget`
  - `buildWidget.metaV2.codeRelations.usageLinks` includes the link to `Widget`
- This specifically catches stale metaV2 after inference.

---

## 6.4 Heuristic noise reduction: reserved words + code dictionaries + token classification

This subsection affects:
- Call/usage extraction in heuristic parsers (C-like, Go, Java, Kotlin, C#, Lua, Perl, PHP, Ruby, Shell, TypeScript).
- Tokenization quality (identifier splitting / keyword noise).

### 6.4.1 Task: Promote per-language reserved word sets to “complete” keyword lists

**Current problem:** the existing `*_CALL_KEYWORDS` and `*_USAGE_SKIP` sets are partial.  
This causes false-positive calls/usages for keywords and builtin type names.

**Primary implementation locations to update:**
- C-like:
  - `src/index/constants.js` → `CLIKE_CALL_KEYWORDS`, `CLIKE_USAGE_SKIP`
- TypeScript:
  - `src/lang/typescript/constants.js` → `TS_CALL_KEYWORDS`, `TS_USAGE_SKIP`, `TS_FLOW_SKIP`
- Others (inline in file):
  - `src/lang/csharp.js` → `CSHARP_CALL_KEYWORDS`, `CSHARP_USAGE_SKIP`
  - `src/lang/go.js` → `GO_CALL_KEYWORDS`, `GO_USAGE_SKIP`
  - `src/lang/java.js` → `JAVA_CALL_KEYWORDS`, `JAVA_USAGE_SKIP`
  - `src/lang/kotlin.js` → `KOTLIN_CALL_KEYWORDS`, `KOTLIN_USAGE_SKIP`
  - `src/lang/lua.js` → `LUA_CALL_KEYWORDS`, `LUA_USAGE_SKIP`
  - `src/lang/perl.js` → `PERL_CALL_KEYWORDS`, `PERL_USAGE_SKIP`
  - `src/lang/php.js` → `PHP_CALL_KEYWORDS`, `PHP_USAGE_SKIP`
  - `src/lang/ruby.js` → `RUBY_CALL_KEYWORDS`, `RUBY_USAGE_SKIP`
  - `src/lang/shell.js` → `SHELL_CALL_KEYWORDS`, `SHELL_USAGE_SKIP`
  - Rust (flow/dataflow only):
    - `src/lang/rust.js` → `RUST_USAGE_SKIP`

**Missing comprehensive reserved-word sets (add these):**
- Objective-C (`src/lang/clike.js` / `src/lang/tree-sitter` usage; no `*_RESERVED_WORDS` yet)
- Swift (`src/lang/swift.js` only has `SWIFT_DECL_KEYWORDS` + tiny skip set)
- C++ (currently only covered implicitly by `CLIKE_RESERVED_WORDS`)
- JavaScript (`src/lang/javascript.js` has no reserved-word set)
- Python (`src/lang/python.js` has no reserved-word set)
- Rust (has `RUST_USAGE_SKIP` only; no full reserved list)
- SQL dialects: Postgres / MySQL / SQLite (`src/lang/sql.js` has no reserved-word sets)
- CSS (`src/lang/css.js` has no reserved-word set)
- HTML (`src/lang/html.js` has no reserved-word set)

**Required refactor (recommended for maintainability):**
- [x] For each language module above, introduce a single exported `*_RESERVED_WORDS` (or `*_KEYWORDS`) set that is the **superset**.
- [x] Define:
  - `*_CALL_KEYWORDS = RESERVED_WORDS ∩ {things that can appear before “(” in syntax but are not calls}`
  - `*_USAGE_SKIP = RESERVED_WORDS ∪ {primitive types, literals, ultra-common words}`  
    (keep it *strictly* a superset to reduce false positives)
- [x] Ensure all sets are:
  - lowercased where language is case-sensitive (except where language semantics require case, e.g., Rust `Self`)
  - sorted in source for readability (alphabetical)
  - have no duplicates

**Acceptance criteria:**
- Fewer false positives in `calls`/`usages` for the targeted languages.
- No existing tests regress.

**Add regression tests (must add):**
- `tests/relations/keyword-skip-heuristics.test.js` (new)

Design:
- For each language that uses regex `\bNAME\s*\(` call extraction, feed a snippet that contains:
  - control structures that look like calls: `if(...)`, `for(...)`, `while(...)`, etc
  - real calls: `foo(...)`, `obj.foo(...)`
- Assert that:
  - control structure keywords are **not** included in `calls`
  - `foo`/`obj.foo` **are** included

Implementation hint:
- Use the existing relation entrypoints:
  - C-like: `src/lang/clike.js` exports `buildCLikeRelations` (or equivalent; see file exports)
  - Go: `buildGoRelations(...)` or the module export that returns `{ calls, usages }`
  - etc.

If you don’t have a clean exported function, test the internal `collect*CallsAndUsages()` functions directly.

---

### 6.4.2 Task: Per-language “code dictionaries” for identifier segmentation

**Goal:** Improve identifier splitting (e.g., `HTTPRequest` → `http` + `request`, `userID` → `user` + `id`)  
**without changing core scoring/ranking logic** (only segmentation quality).

**Current segmentation engine:** `src/shared/tokenize.js`
- `splitWordsWithDict(token, dictWords, config)` is already used by:
  - index-time tokenization: `src/index/build/tokenization.js`
  - query-time tokenization: `src/retrieval/query.js`

**Proposed design:**
- [x] Add a second dictionary source: **code dictionaries**, separate from natural-language dictionaries.
- [x] Code dictionaries are loaded, and applied only when tokenizing code (index mode `code`).
- [x] Provide:
  - `common-code.txt` (shared abbreviations): `http`, `url`, `uuid`, `json`, `yaml`, `html`, `css`, `sql`, `api`, `cli`, `ui`, `db`, `rpc`, `grpc`, `tls`, `ssl`, `jwt`, `oauth`, etc.
  - Per-language additions: `go.txt`, `java.txt`, `typescript.txt`, etc.

**Where to implement:**
- Dictionary path discovery:
  - Extend `tools/dict-utils/paths/dictionaries.js` (or add sibling `code-dictionaries.js`)
  - Add config shape to `tools/dict-utils/config/schema` (if present) or document it in roadmap.
- Runtime load:
  - `src/index/build/runtime/runtime.js` → `loadDictionaryWords(...)` currently loads `dictWords`
  - Add `codeDictWords` and/or `codeDictWordsByLanguage`
- Tokenization:
  - `src/index/build/tokenization.js`:
    - When `mode === "code"`, pass a dictionary set that unions:
      - natural dict words (`dictWords`)
      - common code dict
      - effective-language-specific code dict (if any)
  - Ensure worker tokenization has access too:
    - `src/index/build/workers/indexer-worker.js` uses `createTokenizationContext()`

**Acceptance criteria:**
- Turning on code dictionaries improves segmentation for representative identifiers.
- Prose segmentation is unaffected unless explicitly configured.

**Add tests (must add):**
- `tests/tokenize-code-dictionaries.test.js` (new)
  - Verify that with a code dictionary containing `http` and `request`, `HTTPRequest` splits to include `http` and `request`.
  - Verify that with code dictionaries disabled, splitting falls back to existing behavior.

---

### 6.4.3 Task: Token classification (keyword vs identifier vs operator) + weighting

**Goal:** Keep keywords/operators searchable but reduce their ranking impact (keyword-noise control).

**Core requirements:**
- [x] Add classification for code tokens into at least:
  - `identifier`
  - `keyword`
  - `operator`
  - `literal` (numbers/strings)
- [x] Use Tree-sitter token/node types when available, **fallback** to keyword lists only when necessary.
  - Tree-sitter config: `src/lang/tree-sitter/config.js` lists supported `TREE_SITTER_LANGUAGE_IDS`.
- [x] Keep keywords indexable but **down-weight** them relative to identifiers.

#### Proposed implementation strategy (fits current architecture)

**A) Extend tokenization output to carry typed token buckets**
- Modify `src/index/build/tokenization.js`:
  - Currently returns `{ tokens, frequencies, positions, totalTokens }`
  - Extend to also return:
    - `identifierTokens` (array)
    - `keywordTokens` (array)
    - `operatorTokens` (array)
  - `tokens` should continue to exist for backward compatibility (initially keep it as the union).

**B) Feed typed buckets into `fieldTokens`**
- Modify `src/index/build/file-processor/assemble.js` `buildChunkPayload()`:
  - Currently sets `fieldTokens = { name, signature, doc, comment, body }`
  - Add new fields:
    - `fieldTokens.keyword = keywordTokens`
    - `fieldTokens.operator = operatorTokens`
  - Decide what `body` should contain:
    - **Recommended final shape:** `body = identifierTokens` only
    - But do this behind a config flag for compatibility (see below).

**C) Build field postings for new token fields**
- Modify `src/index/build/state.js`:
  - `fieldPostings` currently has `name`, `signature`, `doc`, `comment`, `body`.
  - Add `keyword` and `operator` maps (or make this dynamic by iterating keys from `chunk.fieldTokens`).
- Ensure `src/index/build/postings.js` writes `field_postings.json` with the additional fields.

**D) Retrieval: add default weights for new fields**
- Modify `src/retrieval/query-intent.js`:
  - Extend `DEFAULT_FIELD_WEIGHTS` to include:
    - `keyword`: small weight (e.g., 0.15–0.35)
    - `operator`: tiny weight (e.g., 0.05) or 0 (indexable but not scoring)
- Ensure `src/retrieval/pipeline.js` still operates if these fields are missing (older index).

**E) Compatibility plan**
- Add config flag (suggested):
  - `indexing.postings.tokenClassification.enabled` (default: `false` initially)
- When disabled:
  - Keep current behavior: `body = tokens` (union), no new fields required.
- When enabled:
  - `body = identifierTokens`
  - `keyword`/`operator` fields populated and weighted.

**Acceptance criteria:**
- Queries with only identifiers behave the same or better.
- Queries that are mostly keywords (e.g., `async await`) still return results, but keyword-only matches don’t dominate ranking.

**New tests (must add):**
1. `tests/tokenization/token-classification-tree-sitter.test.js`
   - Feed a small snippet in a Tree-sitter-supported language (e.g., JS or Go).
   - Assert that tokens are classified as expected:
     - identifiers go to `identifierTokens`
     - `if`, `for`, `return` go to `keywordTokens`
     - `=>`, `.`, `::`, `(`, `)` go to `operatorTokens` (depending on which operators you choose to index)
2. `tests/retrieval/keyword-downweighting.test.js`
   - Build a tiny synthetic index with two chunks:
     - Chunk A: many keyword tokens, few identifiers
     - Chunk B: fewer keywords, matching identifiers
   - Query for identifiers + keyword; assert chunk B ranks above A when classification is enabled.

---

## 6.5 CI-Long lane: isolate long-running tests

### 6.5.1 Task: Create a “CI-Long” lane that runs only tests tagged `long`

**Why:** Long tests slow PR feedback; they belong in scheduled/nightly lanes.

**Source of truth for “long”:**
- Tag rules in `tests/run.rules.jsonc` under `"tagRules"` include tag `"long"`.

**Required changes (recommended design: lane alias)**
- [x] Update `tests/run.rules.jsonc`:
  - Add `"ci-long"` to `"knownLanes"`.
- [x] Update `tests/run-discovery.js` `resolveLanes()`:
  - Treat `ci-long` the same as `ci` (expand to `unit`, `integration`, `services`).
- [x] Update `tests/run.js`:
  - When lane `ci-long` is requested, automatically add `--tag long` (as if user passed it).
  - Ensure `--exclude-tag` still works as expected.
- [x] Add npm script in `package.json`:
  - `"test:ci-long": "node tests/run.js --lane ci-long"`
- [x] Add a GitHub Actions workflow lane/job (choose one):
  - **Option A:** Add to `.github/workflows/nightly.yml` (best): run `npm run test:ci-long` on all OSes.
  - **Option B:** Add a separate scheduled workflow `.github/workflows/ci-long.yml`.

**Acceptance criteria:**
- `npm run test:ci-long` runs **only** tests tagged `long`.
- PR CI remains fast (ci-lite).
- Nightly (or scheduled) runs include ci-long.

**Implementation references:**
- Tags/lane system:
  - `tests/run.rules.jsonc`
  - `tests/run-discovery.js`
  - `tests/run.js`

---

## Appendix: Suggested “complete” reserved word lists (copy/paste seeds)

> These are intended as **seed lists** to prevent having to web-search during implementation.  
> Prefer Tree-sitter classification where possible, but keep these sets for heuristic parsers.

### JavaScript / TypeScript (seed keywords)
```
await break case catch class const continue debugger default delete do else enum export extends false finally for function if import in instanceof new null return super switch this throw true try typeof var void while with yield let
as implements interface package private protected public static
any boolean bigint number object string symbol unknown never
keyof readonly infer satisfies asserts is require namespace module type from of get set constructor declare abstract override
```

### C / C++ (seed keywords)
```
auto break case char const continue default do double else enum extern float for goto if inline int long register restrict return short signed sizeof static struct switch typedef union unsigned void volatile while
_Alignas _Alignof _Atomic _Bool _Complex _Generic _Imaginary _Noreturn _Static_assert _Thread_local
alignas alignof and and_eq asm bitand bitor bool catch char8_t char16_t char32_t class compl concept const_cast consteval constexpr constinit co_await co_return co_yield decltype delete dynamic_cast explicit export false friend import module mutable namespace new noexcept not not_eq nullptr operator or or_eq private protected public reinterpret_cast requires static_assert static_cast template this thread_local throw true try typeid typename using virtual wchar_t xor xor_eq final override
```

### Go (seed keywords + predeclared)
```
break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var
nil true false iota
append cap close complex copy delete imag len make new panic print println real recover
bool byte complex64 complex128 error float32 float64 int int8 int16 int32 int64 rune string uint uint8 uint16 uint32 uint64 uintptr any
```

### Java (seed)
```
abstract assert boolean break byte case catch char class const continue default do double else enum extends final finally float for goto if implements import instanceof int interface long native new package private protected public return short static strictfp super switch synchronized this throw throws transient try void volatile while
true false null
var record yield sealed permits non-sealed
module open requires exports opens to uses provides with transitive
```

### Kotlin (seed)
```
as as? break class continue do else false for fun if in !in interface is !is null object package return super this throw true try typealias val var when while
by catch constructor delegate dynamic field file finally get import init param property receiver set setparam where
actual abstract annotation companion const crossinline data enum expect external final infix inline inner internal lateinit noinline open operator out override private protected public reified sealed suspend tailrec vararg value
```

### C# (seed)
```
abstract as base bool break byte case catch char checked class const continue decimal default delegate do double else enum event explicit extern false finally fixed float for foreach goto if implicit in int interface internal is lock long namespace new null object operator out override params private protected public readonly ref return sbyte sealed short sizeof stackalloc static string struct switch this throw true try typeof uint ulong unchecked unsafe ushort using virtual void volatile while
add alias ascending async await by descending dynamic equals from get global group into join let nameof on orderby partial remove select set value var when where yield record init with
```

### Lua (seed)
```
and break do else elseif end false for function goto if in local nil not or repeat return then true until while
```

### PHP (seed)
```
__halt_compiler abstract and array as break callable case catch class clone const continue declare default die do echo else elseif empty enddeclare endfor endforeach endif endswitch endwhile eval exit extends final finally fn for foreach function global goto if implements include include_once instanceof insteadof interface isset list match namespace new or print private protected public readonly require require_once return static switch throw trait try unset use var while xor yield yield from
true false null
```

### Ruby (seed)
```
BEGIN END alias and begin break case class def defined? do else elsif end ensure false for if in module next nil not or redo rescue retry return self super then true undef unless until when while yield
__FILE__ __LINE__ __ENCODING__
```

### Shell (bash/sh seed)
```
if then else elif fi for while until do done case esac in select function time coproc
break continue return exit shift eval exec trap wait local declare typeset readonly export set unset source
true false
```

### Perl (seed)
```
my our use sub package if elsif else unless while until for foreach continue do given when default
next last redo goto return
BEGIN END INIT CHECK UNITCHECK
die warn print say
```

---



## Phase 7 — Embeddings + ANN unification

This section is a **fully expanded, implementation-ready** rewrite of the Phase 7 roadmap. 

**Primary goals:**
- Make embedding generation **build-scoped, deterministic, and resumable** (service queue or inline).
- Make ANN backends **consistent** (same target vectors, same candidate filtering semantics, same readiness signals).
- Make the artifact surface **manifest-first** and contract-compliant (no “guessing” filenames in strict mode).
- Remove quantization/normalization ambiguity so that outputs are **correct, stable, and comparable**.

---

### Objective

Unify embeddings and ANN artifacts across all build paths (inline indexing, build-embeddings, and service queue) so that:

1. **Index build outputs are deterministic**
   - Embedding jobs always target an explicit build root and index directory.
   - Cached embeddings are keyed by an explicit identity key that includes model and quantization settings.
   - Incremental updates and full builds produce the same embedding artifacts.

2. **ANN backends behave consistently**
   - Candidate filtering behaves the same across HNSW and LanceDB.
   - ANN target selection aligns with `denseVectorMode` (merged/doc/code/auto).
   - “ANN-ready” state is clearly signaled in `index_state.json` and the manifest.

3. **Artifact discovery is contract-compliant**
   - Strict discovery uses `pieces/manifest.json` (no directory scanning / filename guessing).
   - Embeddings/ANN artifacts are included in the manifest when present, absent when not.

---

### Exit criteria

All items must be satisfied:

- ✅ **Embedding jobs are build-scoped**
  - `tools/indexer-service.js` uses the job payload to run build-embeddings **against the correct build root** even if builds/current.json changes.
  - Queue payload format is versioned and validated (`embeddingPayloadFormatVersion`).

- ✅ **No quantization overflow / wrap**
  - Quantization levels are clamped to `[2, 256]` in every path that quantizes vectors.
  - No path writes >255 values into a `Uint8Array` or “uint8 JSON” vector artifact.

- ✅ **Normalization is consistent**
  - If `embeddingIdentity.normalize === true`, all stored vectors used for ANN and exact ranking are normalized (or explicitly documented and tested otherwise).

- ✅ **Manifest completeness**
  - If an ANN backend artifact exists (HNSW bin, LanceDB directory, SQLite-vec table marker), the manifest includes a corresponding entry (and any required meta entry).
  - If it does not exist, the manifest does not list it.

- ✅ **Strict mode compliance**
  - Retrieval and validation do not guess filenames in strict mode; they locate artifacts through the manifest.

- ✅ **Parity tests pass**
  - Ranking parity tests demonstrate that Dense vs HNSW vs LanceDB are consistent on deterministic fixtures (within acceptable error bounds for ANN).

---

## 7.0 Foundation: contracts, terminology, and execution order

### 7.0.1 Source-of-truth hierarchy and conflict resolution rules

Phase 7 touches multiple “spec surfaces”. Use this hierarchy when conflicts arise:

1. **docs/contracts/public-artifact-surface.md**  
   - Canonical rule: strict tooling must discover artifacts via the manifest (no guessing).  
2. **src/contracts/** (runtime validators + schema defs)  
   - Canonical for what the code *currently* enforces.
3. **docs/guides/embeddings.md** and **docs/guides/search.md**  
   - Operational guidance. If it conflicts with (1), update the guide.
4. **Current implementation**  
   - If code is *ahead* of docs (e.g., it already writes an artifact but docs omit it), update docs/contracts to match the intended public surface.
   - If code is *behind* docs/contracts, update code to match contracts.

**Explicit Phase 7 conflicts discovered and resolution choices:**
- **Conflict A:** Embedding queue `indexRoot` meaning is inconsistent (pipeline passes per-mode index dir; build-embeddings `--index-root` expects base build root).  
  ✅ Resolution: **Rename/clarify fields** in the job payload (`buildRoot` as base; `indexDir` as per-mode). Update tests + worker accordingly. This removes ambiguity and matches build-embeddings behavior.
- **Conflict B:** `tools/build-embeddings/manifest.js` currently filters entries by `ARTIFACT_SCHEMA_DEFS`, which omits non-JSON artifacts like HNSW `.bin` and LanceDB directories.  
  ✅ Resolution: **Manifest must include these artifacts**. Update manifest writer to include them via an allowlist even if they are not JSON-schema-validated, and update docs/contracts to explicitly list them as part of the public surface.
- **Conflict C:** Retrieval loaders read many JSON artifacts via direct filesystem reads (bypassing manifest), contradicting “manifest-first”.  
  ✅ Resolution: In strict mode, retrieval must use `src/shared/artifact-io.js` manifest-based resolvers for all artifacts it loads (JSON and non-JSON).

### 7.0.2 Terminology

To prevent recurring confusion, Phase 7 standardizes these terms:

- **repoRoot**: The repository being indexed/searched.
- **buildRoot**: A single build output root (e.g., `<repo>/builds/<buildId>`). This is the root that contains `index-code`, `index-prose`, etc.
- **indexDir**: A per-mode directory inside buildRoot, e.g.:
  - `<buildRoot>/index-code`
  - `<buildRoot>/index-prose`
- **mode**: One of `code | prose | extracted-prose | records` (Phase 7 primarily targets code + prose).
- **vector variant / target**:
  - `merged`: merged embedding vector for a chunk
  - `code`: code-only vector
  - `doc`: doc-only vector
- **denseVectorMode**: How to select the vector variant for ranking:
  - `merged | code | doc | auto`
  - `auto` is resolved per query intent (and/or mode-specific fallback).
- **ANN backend**: `lancedb | hnsw | sqlite-vec | dense | none` (exact list depends on optional deps and configuration).

### 7.0.3 Capability matrix (post-Phase 7 required behavior)

After Phase 7, these capabilities must hold:

- Dense exact ranking: supports `merged/doc/code` (already possible via `resolveDenseVector()` once `denseVectorMode` is wired through).
- LanceDB ANN: supports `merged/doc/code` (already built and selectable via `resolveLanceDbTarget()`).
- HNSW ANN: **must have an explicit, documented target mapping**:
  - Build and load HNSW indices for `merged/doc/code` so it can match LanceDB behavior.


### 7.0.4 Recommended execution order

Order tasks so that cross-cutting foundational changes land first:

1. **7.2 Artifact contract + manifest completeness** (must exist before strict loaders can be updated)
2. **7.3 Quantization invariants** (prevents corrupt outputs and invalid caches)
3. **7.4 Normalization policy consistency** (required before parity tests)
4. **7.1 Embedding job scoping + worker behavior** (service correctness)
5. **7.5 LanceDB robustness**
6. **7.6 HNSW compatibility + observability**
7. **7.7 Backend policy + ranking equivalence**
8. **7.8 Storage resilience**

---

### 7.0.5 Test lane classification (mandatory)

All new Phase 7 tests must land in the intended CI lane.

- Update `tests/run.rules.jsonc` to map any new test files (do not rely on ambiguous filenames alone).
- If a test is intentionally placed to match an existing lane rule, verify it in `npm test -- --list-lanes` and note it in the test section.
- Add a shared optional-deps test helper (e.g., `tests/helpers/optional-deps.js`) so skip behavior is consistent across tests.

## 7.1 Embedding jobs are build-scoped, deterministic, idempotent

### Why this exists

Current embedding service flow is not fully build-scoped:
- `src/index/build/indexer/pipeline.js` enqueues an embedding job, but the worker (`tools/indexer-service.js`) ignores job buildRoot/indexRoot and calls `tools/build-embeddings.js` without `--index-root`.
- Queue tests currently allow inconsistent `buildRoot` vs `indexRoot` values, which hides real scoping bugs.

### 7.1.1 Define the embedding job payload schema (versioned)

**Touchpoints**
- `src/index/build/indexer/embedding-queue.js` (~L1–L49)
- `tools/service/queue.js` (~L1–L270)
- `tools/indexer-service.js` (~L1–L441)
- Tests: `tests/embedding-queue.js` (~L1–L51), `tests/embedding-queue-defaults.js` (~L1–L37)

**New canonical job payload fields** (JSON):
```json
{
  "type": "embeddings",
  "embeddingPayloadFormatVersion": 2,
  "repoRoot": "/abs/path/to/repo",
  "buildId": "b123",
  "buildRoot": "/abs/path/to/repo/builds/b123",
  "mode": "code",
  "indexDir": "/abs/path/to/repo/builds/b123/index-code",
  "embeddingIdentity": { "...": "..." },
  "embeddingIdentityKey": "sha1-or-similar",
  "configHash": "sha1-of-effective-config",
  "repoProvenance": {
    "gitSha": "optional",
    "dirty": false,
    "toolVersion": "optional"
  },
  "createdAt": "2026-01-30T12:34:56.000Z",
  "updatedAt": "2026-01-30T12:34:56.000Z",
  "attemptCount": 0,
  "lastError": null
}
```

**Hard requirements**
- `buildRoot` MUST be an absolute path.
- `indexDir` MUST be an absolute path AND MUST be inside `buildRoot` (validate via `path.relative()`; reject `..` escape).
- `mode` MUST be one of the supported modes.
- `embeddingIdentityKey` MUST match `buildEmbeddingIdentityKey(embeddingIdentity)` exactly.
- `configHash` MUST be stable for the effective embedding config.
- `embeddingPayloadFormatVersion` MUST be set (defaulted, but not omitted).

**Compatibility behavior**
- If a job is missing `embeddingPayloadFormatVersion`, treat it as version 1 and:
  - If it has `indexRoot` (legacy), interpret:
    - If `indexRoot` ends with `/index-code` or `/index-prose`, treat it as `indexDir`.
    - Else treat it as `buildRoot`.
  - Populate missing fields where safely derivable.
  - Emit a warning once per worker run that legacy payloads are being upgraded.

### 7.1.2 Fix the enqueue site to emit correct fields

**Touchpoints**
- `src/index/build/indexer/pipeline.js` (~L1–L326) (search: `enqueueEmbeddingJob({`)
- `src/index/build/indexer/embedding-queue.js` (~L1–L49)

**Current bug**
- Pipeline passes `indexRoot: outDir` where `outDir` is already the per-mode index directory. This is incompatible with build-embeddings `--index-root` semantics and breaks any future “join index dir” logic.

**Required changes**
- In `pipeline.js` when calling `enqueueEmbeddingJob`, pass:
  - `buildRoot: runtime.buildRoot` (already exists on runtime)
  - `indexDir: outDir` (rename from indexRoot)
- In `embedding-queue.js`, accept `indexDir` (new) and either:
  - Disallow legacy `indexRoot` input, OR
  - Support both but normalize to canonical `indexDir`.

**Also update**
- Validate `indexDir` exists (or at least that its parent buildRoot exists) before enqueueing. If missing, treat as programmer error and throw (this prevents silent jobs that can never run).

### 7.1.3 Worker must run build-embeddings against the correct build root

**Touchpoints**
- `tools/indexer-service.js` (~L1–L441) (function `runBuildEmbeddings`)
- `tools/build-embeddings/cli.js` (~L1–L95) (already supports `--index-root`)
- `tools/build-embeddings/runner.js` (~L1–L763) (already expects indexRoot base)

**Required changes**
- Update `runBuildEmbeddings({ job })` to include:
  - `--index-root <job.buildRoot>`  
    (NOT `job.indexDir`; build-embeddings runner will derive per-mode indexDir.)
- If job includes `indexDir`, pass it only for validation/logging; do not use as the base index root.
- Ensure the worker runs `--mode <job.mode>` and uses the job’s `repoRoot` (or `repo`).
- If `job.repoRoot` and the worker’s `--repo` mismatch, the worker should:
  - prefer `job.repoRoot` if present
  - warn if `--repo` differs (avoid “wrong repo” processing)

**Safety requirement**
- If `job.buildRoot` does not exist, mark job failed with `lastError` explaining missing build root and do not retry indefinitely (cap attempts).

### 7.1.4 Index state should clearly represent “pending embeddings”

**Touchpoints**
- `src/index/build/indexer/steps/write.js` (~L1–L101) (writes initial index_state during stage2)
- `tools/build-embeddings/runner.js` (~L1–L763) (updates index_state during stage3)

**Required state machine**
- Stage2 build when embeddings are configured to run later via service:
  - `index_state.embeddings.enabled = true`
  - `index_state.embeddings.ready = false`
  - `index_state.embeddings.pending = true`  ✅ add this
  - `index_state.embeddings.service = true`
  - `index_state.embeddings.mode = <mode>`
  - `index_state.embeddings.embeddingIdentity` and `.embeddingIdentityKey` SHOULD be present if known at stage2.
- Stage3 success:
  - `enabled = true`
  - `ready = true`
  - `pending = false`
  - `updatedAt` set (already)
- Stage3 failure:
  - `enabled = true`
  - `ready = false`
  - `pending = false` (job completed but failed) OR keep `pending=true` only if the job will be retried.
  - `lastError` set (new)

**Note:** Retrieval currently uses `embeddingsReady = embeddingsState?.ready !== false && embeddingsState?.pending !== true`. That logic assumes `pending` exists; Phase 7 makes it real.

### 7.1.5 Tests for build scoping and worker correctness

**Update existing tests**
- `tests/embedding-queue.js`
  - Must require that when `enqueueEmbeddingJob({ runtime, mode, indexDir })` is called:
    - job.buildRoot equals runtime.buildRoot
    - job.indexDir equals resolved indexDir
    - job.indexDir is within job.buildRoot
  - Remove the current test behavior that allows buildRoot/indexRoot mismatch.
- `tests/embedding-queue-defaults.js`
  - Assert that missing optional fields are filled:
    - `embeddingPayloadFormatVersion` is set
    - `attemptCount` default 0
    - `createdAt` and `updatedAt` are ISO strings

**Add new tests**
- `tests/indexer-service-embedding-job-uses-build-root.js` (new)
  - Create two builds (b1 and b2) under a temp repo
  - Create a job targeting buildRoot=b1
  - Simulate builds/current.json pointing at b2
  - Run `tools/indexer-service.js --once --queue embeddings` (or equivalent)
  - Assert embeddings artifacts were written under build b1 (not b2)
  - Assert job is marked completed and `index_state.json` under b1 indicates `ready=true`.

---

## 7.2 Artifact contract parity for embeddings + ANN

### Why this exists

Contracts require manifest-first discovery. Today:
- `tools/build-embeddings/manifest.js` tries to add embedding pieces but filters them by `ARTIFACT_SCHEMA_DEFS`, excluding important non-JSON artifacts.
- Retrieval/validation still open some artifacts by guessed filenames.

Phase 7 makes embeddings and ANN artifacts fully discoverable via the manifest.

### 7.2.1 Define the canonical public artifact names for embeddings + ANN

**Specs to update**
- `docs/contracts/artifact-schemas.md`
- `docs/contracts/public-artifact-surface.md`

**Code to update**
- `src/contracts/registry.js` and/or `src/contracts/schemas/artifacts.js` (if adding names)
- `tools/build-embeddings/manifest.js`
- `src/shared/artifact-io/manifest.js` (if adding helpers for binary/dir artifacts)
- `src/retrieval/cli-index.js`, `src/retrieval/cli/load-indexes.js`, `src/index/validate.js`

**Canonical names (Phase 7)**
These names are used as `manifestEntry.name` and in code when resolving artifacts:

Dense vectors (quantized uint8 JSON, with vectors embedded):
- `dense_vectors` → `dense_vectors_uint8.json`
- `dense_vectors_doc` → `dense_vectors_doc_uint8.json`
- `dense_vectors_code` → `dense_vectors_code_uint8.json`

HNSW (non-JSON + JSON meta):
- `dense_vectors_hnsw` → `dense_vectors_hnsw.bin`
- `dense_vectors_hnsw_meta` → `dense_vectors_hnsw.meta.json`
- `dense_vectors_doc_hnsw` → `dense_vectors_doc_hnsw.bin`
- `dense_vectors_doc_hnsw_meta` → `dense_vectors_doc_hnsw.meta.json`
- `dense_vectors_code_hnsw` → `dense_vectors_code_hnsw.bin`
- `dense_vectors_code_hnsw_meta` → `dense_vectors_code_hnsw.meta.json`

LanceDB (directories + JSON meta):
- `dense_vectors_lancedb` → `dense_vectors.lancedb/`
- `dense_vectors_lancedb_meta` → `dense_vectors.lancedb.meta.json`
- `dense_vectors_doc_lancedb` → `dense_vectors_doc.lancedb/`
- `dense_vectors_doc_lancedb_meta` → `dense_vectors_doc.lancedb.meta.json`
- `dense_vectors_code_lancedb` → `dense_vectors_code.lancedb/`
- `dense_vectors_code_lancedb_meta` → `dense_vectors_code.lancedb.meta.json`

SQLite vector extension ANN presence:
- This is DB state, not a file artifact. Represent it in `index_state.embeddings.backends.sqliteVec` and optionally as a manifest “marker”:
  - `dense_vectors_sqlite_vec_meta` → `dense_vectors_sqlite_vec.meta.json` (new optional)  
    (If added, it documents dims/count and table name; it is optional because it depends on build options and sqlite configuration.)

**Important:** Even if you do not add JSON schemas for binary/dir artifacts, their NAMES must be part of the public artifact surface and must appear in the manifest when present.

### 7.2.2 Update the embeddings manifest writer to include non-JSON artifacts

**Touchpoints**
- `tools/build-embeddings/manifest.js` (~L1–L111)

**Current behavior**
- Builds `embeddingPieces`, then filters by `ARTIFACT_SCHEMA_DEFS` names, which excludes:
  - `dense_vectors_hnsw` (bin)
  - `dense_vectors_lancedb` (dir)
  - and doc/code variants.

**Required behavior**
- Remove or relax the schema-name filter. Replace with a clear allowlist:
  - `const allowed = new Set([...Object.keys(ARTIFACT_SCHEMA_DEFS), ...NON_JSON_PUBLIC_ARTIFACTS]);`
  - where `NON_JSON_PUBLIC_ARTIFACTS` includes the bin/dir names listed above.
- For `format: 'bin'`, add manifest entry if the file exists.
- For `format: 'dir'`, add manifest entry if the directory exists.
- Ensure manifest entries record:
  - `format` as `json|jsonl|bin|dir` (already)
  - `bytes` and `sha256` for files (`bin` and `json`) where feasible
  - For directories, record `entries` count and/or omit bytes (bytes optional); if bytes is recorded, compute deterministically (walk directory sorted).

**Edge cases**
- If `.bak` exists for HNSW, do not add it to manifest as a separate artifact. The `.bak` is an implementation detail. Only the canonical `.bin` path is listed.

### 7.2.3 Update readers to use manifest in strict mode

**Touchpoints**
- `src/retrieval/cli-index.js` (~L1–L416) (file-backed load)
- `src/retrieval/cli/load-indexes.js` (~L1–L368) (LanceDB attach)
- `src/index/validate.js` (~L1–L581)
- `src/shared/artifact-io.js` (~L1–L12) and `src/shared/artifact-io/manifest.js` (~L1–L291)

**Required behavior**
- In strict mode:
  - JSON artifacts are loaded via `loadJsonArrayArtifact`, `loadJsonObjectArtifact`, `loadChunkMeta`, etc.
  - Non-JSON artifacts are *located* via manifest (resolve path), then opened.

**Concrete implementation steps**
1. Add helper(s) in `src/shared/artifact-io.js`:
   - `resolveBinaryArtifactPath(dir, name, { strict })`
   - `resolveDirArtifactPath(dir, name, { strict })`
   These should:
   - in strict mode: require manifest entry and return absolute path
   - in non-strict mode: fall back to legacy filename guessing (only for backward compatibility)
2. Update `src/retrieval/cli-index.js`:
   - Replace `readJsonFile(path.join(dir, 'dense_vectors_uint8.json'))` with `loadJsonObjectArtifact(dir, 'dense_vectors', { strict: true })`
   - Replace HNSW meta load with `loadJsonObjectArtifact(dir, 'dense_vectors_hnsw_meta', { strict: true })`
   - Resolve HNSW bin with `resolveBinaryArtifactPath(dir, 'dense_vectors_hnsw', { strict: true })`
3. Update `src/retrieval/cli/load-indexes.js` attachLanceDb:
   - Resolve `dense_vectors_*_lancedb_meta` through manifest, not direct path join.
   - Resolve the lancedb directory through manifest entry `dense_vectors_*_lancedb`.
4. Update `src/index/validate.js`:
   - For strict validation, require manifest presence for embedding artifacts and use it to locate them.
   - Validation should fail if an artifact exists on disk but is missing from manifest (strict mode).

### 7.2.4 Index state should include embedding identity and backend presence

**Touchpoints**
- `src/index/build/indexer/steps/write.js` (~L1–L101) (stage2)
- `tools/build-embeddings/runner.js` (~L1–L763) (stage3)
- Tests: `tests/embeddings-validate.js` (~L1–L82), `tools/index-validate.js` (~L1–L130) output

**Required new fields**
- `index_state.embeddings.embeddingIdentity` (object)
- `index_state.embeddings.embeddingIdentityKey` (string)
- `index_state.embeddings.backends` (object, example):
```json
{
  "hnsw": { "enabled": true, "available": true, "target": "merged", "dims": 384, "count": 1234 },
  "lancedb": { "enabled": true, "available": true, "target": "code", "dims": 384, "count": 1234 },
  "sqliteVec": { "enabled": true, "available": false }
}
```

**Rules**
- `available` means the artifact is present and loadable.
- `enabled` means config requested it.
- `target` is only required if the backend depends on vector variant selection.

### 7.2.5 Tests for manifest completeness and strict discovery

**Add new tests**
- `tests/manifest-embeddings-pieces.js`
  - Build stage2 index for fixture repo (stub embeddings).
  - Run build-embeddings stage3.
  - Load `<indexDir>/pieces/manifest.json`.
  - Assert it includes entries for:
    - `dense_vectors`
    - `dense_vectors_hnsw` and `dense_vectors_hnsw_meta` (if hnswlib is installed; if not installed, assert they are absent)
    - `dense_vectors_lancedb` and `dense_vectors_lancedb_meta` (if lancedb is installed; else absent)
  - Assert that if `dense_vectors_hnsw.bin` exists, manifest includes it.
  - Assert that if manifest lists it, file exists.

- `tests/retrieval-strict-manifest-embeddings.js`
  - Create an indexDir with embeddings artifacts present but remove `pieces/manifest.json`.
  - Run `search.js` in strict mode (default) and assert it fails with `ERR_MANIFEST_MISSING` (or equivalent).
  - Run `search.js --non-strict` (if supported) and assert it can still run (legacy fallback), but logs a warning.

**Update existing tests**
- `tests/artifact-io-manifest-discovery.test.js`
  - Extend to also verify `dense_vectors` and `dense_vectors_hnsw_meta` cannot be loaded without manifest in strict mode once the loader changes land.

---

## 7.3 Quantization invariants end-to-end

### Why this exists

There are multiple quantization entry points:
- `src/shared/embedding-utils.js` has both `quantizeEmbeddingVector()` (unclamped levels) and `quantizeEmbeddingVectorUint8()` (clamped).
- Several call sites use the unclamped path and then pack into a Uint8Array, which can wrap values.

This phase enforces correct quantization everywhere.

### 7.3.1 Clamp quantization levels globally to [2, 256]

**Touchpoints**
- `src/storage/sqlite/vector.js` (~L1–L71) (function `resolveQuantizationParams`)
- `src/shared/embedding-utils.js` (~L1–L176) (`quantizeEmbeddingVector`, `quantizeEmbeddingVectorUint8`, `dequantizeUint8ToFloat32`)
- `src/index/embedding.js` (~L1–L56) (`quantizeVec`, `quantizeVecUint8`)
- `tools/build-embeddings/embed.js` (~L1–L119)
- `src/storage/sqlite/build/incremental-update.js` (~L1–L567)
- `src/index/build/file-processor/embeddings.js` (~L1–L260)

**Required changes**
1. In `resolveQuantizationParams()`:
   - Clamp `levels` to integer in `[2, 256]`.
   - Rationale: prevents overflow **and** avoids divide-by-zero in `scale = (maxVal - minVal) / (levels - 1)` when `levels <= 1`.
   - If invalid, default to 256.
2. In `quantizeEmbeddingVector()`:
   - Either:
     - clamp internally (same as Uint8 version), OR
     - mark as internal-only and ensure no production path uses it.
   - Phase 7 requirement: **production quantization must not be able to output values >255**.
3. Update `src/index/embedding.js`:
   - Make `quantizeVec()` call the clamped implementation OR remove it in favor of `quantizeVecUint8()` and update call sites.

### 7.3.2 Ensure all stored “uint8 artifacts” are actually uint8-safe

**Artifacts affected**
- `dense_vectors_uint8.json` (`dense_vectors`)
- `dense_vectors_doc_uint8.json` (`dense_vectors_doc`)
- `dense_vectors_code_uint8.json` (`dense_vectors_code`)
- SQLite dense tables written by `tools/build-embeddings/sqlite-dense.js`
- HNSW/LanceDB build paths that dequantize from uint8

**Required changes**
- Update `tools/build-embeddings/embed.js` to quantize using the clamped path.
  - Prefer storing vectors as plain arrays of integers 0..255 in JSON.
- Update `src/storage/sqlite/build/incremental-update.js` to use a clamped quantizer before packing into Uint8Array.

### 7.3.3 Persist quantization metadata where it is needed

Current code often assumes `minVal=-1` and `levels=256`, which breaks if config differs.

**Phase 7 rule**
- Any component that needs to dequantize MUST have access to the exact `(minVal, maxVal, levels)` used (or an equivalent representation).

**Implementation choice**
- Add optional fields to the dense vector artifacts and backend meta files:
  - For `dense_vectors*` artifacts: add `minVal`, `maxVal`, `levels`, and optionally `quantization` object.
  - For HNSW meta and LanceDB meta: add the same quantization fields.
  - This is safe because JSON schemas allow additionalProperties.

**Touchpoints**
- Writers:
  - `tools/build-embeddings/runner.js` (~L1–L763) (when writing dense_vectors*.json and meta)
  - `tools/build-embeddings/hnsw.js` (~L1–L115) (meta output)
  - `tools/build-embeddings/lancedb.js` (~L1–L143) (meta output)
- Readers:
  - `src/retrieval/rankers.js` (~L1–L292) (rankDenseVectors: stop hardcoding `minVal=-1`)
  - `src/retrieval/sqlite-helpers.js` (~L1–L544) (dense meta: stop hardcoding minVal)
  - `tools/build-embeddings/lancedb.js` (~L1–L143) (dequantizeUint8ToFloat32 must use correct quantization)

### 7.3.4 Update LanceDB build to dequantize correctly

**Touchpoints**
- `tools/build-embeddings/lancedb.js` (~L1–L143)

**Required changes**
- `buildBatch()` currently calls `dequantizeUint8ToFloat32(row.vec)` without passing params (defaults to -1..1, 256).
- Update `writeLanceDbIndex()` signature to accept quantization params (or `scale + minVal`), and pass through from `runner.js`.

**Correctness tests**
- A dedicated test should:
  - Configure quantization levels != 256 (e.g., 128) in a temporary repo config
  - Build embeddings and LanceDB index
  - Query LanceDB directly (or via search) and assert results are stable and not obviously degraded vs Dense

### 7.3.5 Tests for quantization invariants

**Update existing tests**
- `tests/quantize-embedding-utils.js` (if exists) or add new:
  - Assert clamping:
    - levels < 2 => 2
    - levels > 256 => 256
  - Assert no value in output exceeds 255.

**Add new test**
- `tests/embedding-quantization-no-wrap.js`
  - Construct an embedding vector with values near 1.0
  - Use quantization levels 512 in config (intentionally invalid)
  - Run the embedding build path that writes JSON and SQLite
  - Assert:
    - dense vectors JSON only contains integers 0..255
    - sqlite dense table values match expected quantization (no modulo wrap)
    - `index_state.embeddings.embeddingIdentity.quantization.levels` shows the clamped value.

---

## 7.4 Normalization policy consistency

### Why this exists

Normalization affects:
- exact dense ranking (dot product expects normalized vectors for cosine equivalence)
- ANN backends (HNSW metric, LanceDB metric)
- caching (embedding identity includes normalize)

### 7.4.1 Define and enforce normalization rules

**Rule 1**
- If `embeddingIdentity.normalize === true`, then:
  - code, doc, and merged vectors MUST be L2 normalized before storage.
  - Any dequantized float vectors used for ANN MUST be normalized (or equivalent).

**Rule 2**
- If `embeddingIdentity.normalize === false`, then:
  - storage may contain raw vectors, but ANN backend selection must respect configured metric.

**Touchpoints**
- `src/shared/embedding-adapter.js` (~L1–L158) (ensures embedding providers normalize)
- `tools/build-embeddings/embed.js` (~L1–L119) (mergeEmbeddingVectors + normalizeEmbeddingVector)
- `src/index/build/file-processor/embeddings.js` (~L1–L260) (inline embeddings path)
- `tools/build-embeddings/runner.js` (~L1–L763) (cache load path where HNSW vectors are dequantized)

**Required changes**
- Ensure build-embeddings cache load path normalizes HNSW float vectors whenever identity.normalize is true, not only when `hnswConfig.space === 'cosine'`.
- Ensure `mergeEmbeddingVectors()` behavior is explicitly specified:
  - If doc vector is missing (zeros), merged should still normalize correctly and not bias scale.
  - Add test coverage.

### 7.4.2 Tests for normalization consistency

**Add test**
- `tests/embedding-normalization-consistency.js`
  - Use stub embeddings that produce a known non-normalized vector.
  - Ensure the pipeline normalizes it before storage when normalize=true.
  - Ensure merged vector equals normalized(mean(code, doc)) within tolerance.

**Update ANN tests**
- `tests/hnsw-ann.js` and `tests/lancedb-ann.js` should assert:
  - embeddings meta includes normalize=true
  - ANN meta metric/space matches expected
  - Query-time similarity ordering matches Dense within tolerance.

---

## 7.5 LanceDB robustness improvements

### Why this exists

Candidate filtering semantics and robustness issues:
- When candidateSet is large and pushdown is disabled, a single fixed-limit query may return fewer than topN matches after filtering.
- Connection caching is not concurrency-safe (race opens).
- Filter clause construction must be safe and correct.

### 7.5.1 Implement iterative overfetch for candidateSet filtering

**Touchpoints**
- `src/retrieval/lancedb.js` (~L1–L180) (function `searchLanceDbCandidates`)

**Required behavior**
- When `candidateSet` is provided:
  - Try pushdown if candidateSet is numeric and <= `LANCE_CANDIDATE_PUSH_LIMIT`.
  - Else run iterative overfetch:
    1. Start with `limit = max(topN*4, topN+10)`.
    2. Execute query with that limit.
    3. Filter results by candidateSet.
    4. If filtered count < topN AND raw results length == limit:
       - increase limit (e.g., x2) up to a cap (candidateCount or a global max).
       - repeat.
     5. Stop when enough results or when limit reaches cap.

**Correctness requirement**
- Deterministic: same inputs yield same outputs (stable sort tie-breakers).
- Efficient: cap iterations (e.g., max 4 passes).

### 7.5.2 Make connection caching concurrency-safe

**Touchpoints**
- `src/retrieval/lancedb.js` (~L1–L180) (`connectionCache`)

**Required changes**
- Store a Promise in the cache while connecting:
  - If concurrent calls happen, they await the same Promise.
- If connection fails, delete cache entry so later attempts can retry.

### 7.5.3 Harden filter construction

**Touchpoints**
- `src/retrieval/lancedb.js` (~L1–L180)

**Required changes**
- Validate `idColumn` is a safe identifier (e.g., `/^[A-Za-z_][A-Za-z0-9_]*$/`).
- Ensure `candidateSet` values are integers, not floats.

### 7.5.4 Tests for LanceDB candidate filtering

**Add new test**
- `tests/lancedb-candidate-filtering.js`
  - Use a stub dataset large enough that candidateSet > push limit.
  - Use a candidateSet that excludes most top hits.
  - Assert:
    - The function still returns topN results within candidateSet (iterative overfetch works).
    - Stats indicate multiple passes were executed (optional metric in logs).

---

### 7.5.5 Acceptance criteria

- Candidate-set filtering works for both small and large candidate sets:
  - If `candidateSet.size >= topN`, the function returns **at least** `topN` results whenever the underlying dataset contains enough matches.
  - If the dataset (or candidateSet) cannot produce `topN` matches, it returns as many as possible without throwing.
- Connection caching is concurrency-safe:
  - Concurrent queries to the same LanceDB directory do not trigger multiple `connect()` calls.
- Pushdown filtering is used when safe:
  - When `candidateSet` is numeric and `candidateSet.size <= LANCE_CANDIDATE_PUSH_LIMIT`, the query uses a `where` clause pushdown.

### 7.5.6 Tests

Add/Update the following tests (names are prescriptive; adjust location if the repo’s test layout requires flat files):

- `tests/unit/lancedb-candidate-filtering.test.js` (new)
  - Exercises iterative overfetch when candidateSet is large.
- `tests/unit/lancedb-connection-cache.test.js` (new)
  - Verifies promise-cached connections prevent double-open under concurrency.
- `tests/unit/lancedb-filter-pushdown.test.js` (new)
  - Verifies pushdown is used only for safe numeric candidate sets.
- `tests/lancedb-ann.js` (existing)
  - Extend assertions if needed to confirm ANN backend is LanceDB and returns stable results.



## 7.6 HNSW signature compatibility and observability

### Why this exists

- `hnswlib-node` API signatures differ across versions; current code may pass the wrong second argument to `readIndexSync`.
- Insert failures are not sufficiently observable.
- Variant selection must align with denseVectorMode if Phase 7 supports doc/code/merged.

### 7.6.1 Make loadHnswIndex tolerant to signature differences

**Touchpoints**
- `src/shared/hnsw.js` (~L1–L160) (function `loadHnswIndex`)
- `src/shared/hnsw.js` (~L1–L160) (function `resolveHnswPaths` if extended to support variants)

**Required changes**
- Detect `readIndexSync` signature:
  - If it expects `(path, maxElements)` then pass maxElements (number).
  - If it expects `(path, allowReplaceDeleted)` then pass boolean.
  - If unknown, try safe fallbacks with try/catch:
    1. call with just `(path)`
    2. call with `(path, maxElements)`
    3. call with `(path, allowReplaceDeleted)`
  - Use meta/config to choose expected dims/count.

**Observability**
- When fallback path is used, log a warning once with:
  - detected arity
  - attempted signatures
  - final chosen signature

### 7.6.2 Build and load HNSW indices for merged/doc/code variants

**Touchpoints**
- Writer:
  - `tools/build-embeddings/runner.js` (~L1–L763)
  - `tools/build-embeddings/hnsw.js` (~L1–L115)
- Reader:
  - `src/retrieval/cli-index.js` (~L1–L416) (HNSW load)
  - `src/retrieval/ann/providers/hnsw.js` (~L1–L27) (already uses idx.hnsw)
  - `src/shared/hnsw.js` (~L1–L160) path resolver

**Required behavior**
- For each mode, if embeddings are ready and HNSW is enabled and available:
  - Build HNSW for:
    - merged vectors (`dense_vectors_hnsw.*`)
    - doc vectors (`dense_vectors_doc_hnsw.*`)
    - code vectors (`dense_vectors_code_hnsw.*`)
- At query-time, select which HNSW index to use based on `resolvedDenseVectorMode`.
  - This mirrors LanceDB behavior and ensures parity.
- Meta files MUST include:
  - dims, count
  - space/metric
  - efSearch/efConstruction/m
  - embeddingIdentityKey (or at least model id)
  - quantization parameters (or scale + minVal)
  - createdAt timestamp

### 7.6.3 Improve insert failure observability

**Touchpoints**
- `tools/build-embeddings/hnsw.js` (~L1–L115)

**Required changes**
- Preserve and rely on the existing atomic write pattern:
  - write to a temp path
  - atomically replace the target `.bin`
  - keep a `.bak` via `replaceFile({ keepBackup: true })`
  - never delete `.bak` unless a subsequent successful load of the new `.bin` is confirmed (and even then, deletion is optional).
- In `writeIndex()`:
  - Collect insertion failures:
    - `{ idx, label, errorMessage }` (label is the chunk id)
  - If count mismatch:
    - write a JSON file alongside meta (e.g., `dense_vectors_hnsw.failures.json`) or include failure summary in meta
    - include top N failures in error message for debugging
- Ensure build fails loudly if insertion failures occur (unless explicitly configured to allow partial indexes).

### 7.6.4 Tests for HNSW variant selection and signature fallback

**Update existing tests**
- `tests/hnsw-ann.js`
  - Once doc/code variants are built, assert those files exist too.
- `tests/hnsw-atomic.js`
  - Ensure .bak fallback still works with new load logic.

**Add new test**
- `tests/hnsw-target-selection.js`
  - Build embeddings with stub embeddings.
  - Force `denseVectorMode=code` and ensure HNSW provider loads the code variant.
  - Force `denseVectorMode=doc` and ensure doc variant loads.

---

### 7.6.5 Acceptance criteria

- HNSW loading is compatible across supported `hnswlib-node` versions:
  - `loadHnswIndex()` successfully loads a valid index regardless of the `readIndexSync` signature variant.
  - If a signature mismatch occurs, fallback logic selects a working call shape and logs a single diagnostic warning.
- Insert failures are observable and actionable:
  - If HNSW insertion fails for any vector, the build either:
    - fails with a clear error including a failure summary, OR
    - (only if explicitly configured) produces a partial index and writes a failures report.
- Atomicity behavior remains correct:
  - If `.bak` exists and the main `.bin` is corrupt, load falls back to `.bak` and still serves results.

### 7.6.6 Tests

Add/Update the following tests:

- `tests/unit/hnsw-load-signature.test.js` (new)
  - Mocks multiple `readIndexSync` signatures and verifies fallback behavior.
- `tests/unit/hnsw-insert-failures.test.js` (new)
  - Forces insertion failures and asserts a failures report (or error) is emitted.
- `tests/hnsw-ann.js` (existing)
  - Extend to verify doc/code variant selection if Phase 7 builds those indices.
- `tests/hnsw-atomic.js` (existing)
  - Must continue to pass; ensures `.bak` fallback behavior remains intact.
- `tests/hnsw-candidate-set.js` (existing)
  - Must continue to pass; candidate-set filtering for HNSW remains correct.



## 7.7 Backend policy and ranking equivalence

### Why this exists

We need a single coherent way to:
- select which dense vectors are used for ranking (`denseVectorMode`)
- select which ANN target is used (must align with denseVectorMode)
- compare backends on a stable fixture (parity)

### 7.7.1 Wire denseVectorMode from config/CLI into retrieval

**Touchpoints**
- `docs/guides/search.md` (~L1–L74) (already references denseVectorMode)
- `docs/guides/embeddings.md` (update to reflect denseVectorMode + strict manifest behavior)
- `docs/config/schema.json` and/or `docs/config/inventory.md` (add `search.denseVectorMode` + CLI flag documentation)
- `src/retrieval/cli/normalize-options.js` (~L1–L273) (currently hardcodes denseVectorMode='merged')
- `src/retrieval/cli/options.js` (~L1–L141) (CLI option definitions)
- `src/retrieval/cli/query-plan.js` (~L1–L205) (already passes denseVectorMode into plan)
- `src/retrieval/query-intent.js` (~L1–L84) (resolveIntentVectorMode)

**Required changes**
- Add CLI option: `--dense-vector-mode merged|doc|code|auto`
  - default should match existing behavior (`merged`) to avoid breaking changes.
- Config key is `search.denseVectorMode` (aligns with existing defaults + docs).
- Ensure `resolvedDenseVectorMode` is computed once and passed into `loadSearchIndexes()` (already).
- Ensure `resolveIntentVectorMode()` never returns `'auto'` when intent provided and valid; else allow 'auto' as fallback.
- Configuration precedence is explicit: **CLI > user config > defaults**, and log when CLI overrides a config value.

### 7.7.2 Ensure ANN backend target selection matches denseVectorMode

**Touchpoints**
- LanceDB:
  - `src/shared/lancedb.js` (~L1–L65) (`resolveLanceDbTarget`) ✅ already supports.
- HNSW:
  - `src/shared/hnsw.js` (~L1–L160) path resolver must support variants.
- SQLite-vec:
  - `tools/build-embeddings/sqlite-dense.js` (~L1–L209) and `tools/vector-extension.js` (~L1–L393)
  - If SQLite-vec is kept as merged-only, it must be documented and enforced.

**Required behavior**
- For each mode, the ANN provider uses the same vector variant as `idx.denseVec` uses.
- If a backend cannot support the selected variant, it must:
  - either fail with a clear error (if explicitly requested), or
  - fall back with an explicit warning (if auto-selected).

### 7.7.3 Parity tests: dense vs ANN backends

**Add new integration test**
- `tests/ann-parity.js`
  - Build index + embeddings for fixture repo with stub embeddings.
  - Run search with:
    - `--ann-backend dense`
    - `--ann-backend lancedb`
    - `--ann-backend hnsw`
  - For each, capture topK doc ids and scores.
  - Assert:
    - Dense is the reference.
    - ANN results contain the same top results in the same order for a deterministic stub embedding (or within a small tolerance / allow ties).
  - Run for multiple `denseVectorMode` values:
    - merged
    - code
    - doc

**Note**
- ANN parity can be relaxed for real embeddings, but for stub embeddings it should be exact or nearly exact.

---

### 7.7.4 Acceptance criteria

- `denseVectorMode` is end-to-end functional:
  - CLI/config can set `merged|doc|code|auto`.
  - The resolved mode is applied consistently to:
    - exact dense ranking
    - ANN target selection (LanceDB + HNSW; SQLite-vec if supported)
- Backend selection is explicit and explainable:
  - If a requested backend cannot satisfy the resolved vector mode, the system either errors clearly or falls back with an explicit warning (depending on selection policy).
- ANN parity tests pass on deterministic fixtures:
  - With stub embeddings, Dense vs ANN results match (or are within the defined tolerance window).

### 7.7.5 Tests

Add/Update tests:

- `tests/integration/ann-parity.test.js` (new; can be implemented as a Node script in this repo’s style)
  - Compares Dense vs LanceDB vs HNSW across vector modes.
- `tests/unit/dense-vector-mode.test.js` (new)
  - Verifies `resolveIntentVectorMode()` and `resolveDenseVector()` behaviors.
- `tests/unit/ann-backend-selection.test.js` (new)
  - Verifies the capability matrix and fallback/error behaviors.
- Existing backend smoke tests:
  - `tests/lancedb-ann.js`
  - `tests/hnsw-ann.js`



## 7.8 Storage resilience (LMDB/SQLite/cache)

### 7.8.1 LMDB mapSize planning

**Touchpoints**
- `tools/build-lmdb-index.js` (~L1–L311)
- `src/storage/lmdb/schema.js` (~L1–L49) (meta keys)
- Tests: `tests/lmdb-backend.js` (~L1–L122), `tests/lmdb-corruption.js` (~L1–L105), `tests/lmdb-report-artifacts.js` (~L1–L125)

**Required behavior**
- Compute a conservative mapSize before writing:
  - Derive an estimate from artifact sizes (chunk_meta, postings, file_relations, etc.)
  - Add overhead factor (e.g., *2.0) and minimum floor (e.g., 256MB)
  - Cap to a maximum if needed
- Write the chosen mapSize into LMDB meta keys so debugging is easier.

### 7.8.2 SQLite dense writer safety for shared DB paths

**Touchpoints**
- `tools/build-embeddings/sqlite-dense.js` (~L1–L209)
- `tools/dict-utils/paths/db.js` (~L1–L62) (resolveSqlitePaths)

**Current risk**
- `DELETE FROM dense_vectors_ann` is unscoped; if code and prose share the same DB file, one run can delete the other mode’s ANN table.

**Required change**
Choose one (documented) approach:
- Preferred: mode-specific ANN table names:
  - `dense_vectors_ann_code`, `dense_vectors_ann_prose`
- Alternative: add `mode` column to vector table and delete by mode (if supported by extension).

Update all query code accordingly:
- `tools/vector-extension.js` query table name must match.

### 7.8.3 Embedding cache preflight metadata

**Touchpoints**
- `tools/build-embeddings/cache.js` (~L1–L26)
- `tools/build-embeddings/runner.js` (~L1–L763)

**Goal**
- Avoid scanning full cache to validate dims/identity each run on huge repos.

**Required change**
- Write a cache meta file per (mode, identityKey), e.g.:
  - `<cacheRoot>/<mode>/cache_meta.json`
  - includes: identityKey, dims, model, normalize, quantization, createdAt
- On startup, runner loads this meta and uses it for fast validation.
- If missing, fall back to current scan and then write meta.

### 7.8.4 Tests for storage resilience

**Update tests**
- LMDB tests should continue to pass; add an assertion that mapSize meta exists (if added).
- Add a new test for shared SQLite DB path configuration:
  - Configure codeDbPath == proseDbPath in a temp user config
  - Build embeddings for code and prose
  - Assert both modes’ ANN tables exist and are not deleted by the other.

---

### 7.8.5 Acceptance criteria

- LMDB build is resilient:
  - `tools/build-lmdb-index.js` chooses a mapSize that prevents MapFull errors on Phase 7 fixtures.
  - The chosen mapSize is recorded in LMDB metadata for debugging.
- SQLite ANN tables are mode-safe:
  - If code and prose share a DB file, running embeddings build for one mode does not delete the other mode’s ANN data.
- Cache preflight avoids full scans in the common case:
  - When cache meta exists, runner does not scan the entire cache to validate dims/identity.

### 7.8.6 Tests

Add/Update tests:

- `tests/unit/lmdb-mapsize.test.js` (new)
  - Builds LMDB for a fixture repo and asserts no MapFull and that mapSize meta is present.
- `tests/unit/sqlite-ann-mode-scope.test.js` (new)
  - Configures shared DB paths and asserts both modes’ ANN tables remain intact.
- `tests/unit/cache-preflight-meta.test.js` (new)
  - Ensures cache meta is written and later used to avoid scanning.
- Existing LMDB tests (must continue to pass):
  - `tests/lmdb-backend.js`
  - `tests/lmdb-corruption.js`
  - `tests/lmdb-report-artifacts.js`
- Storage resilience integration test:
  - `tests/storage/embeddings-backend-resilience.test.js` (new)
    - Simulates partial backend failures (e.g., LanceDB build fails, HNSW succeeds) and asserts:
      - index_state advertises only available backends
      - retrieval does not attempt to use missing backend

### 7.8.7 Edge cases and fallback behavior

- Partial backend build failure:
  - If one backend fails (e.g., LanceDB directory missing/corrupt) but dense vectors exist:
    - `index_state.embeddings.ready` may still be true (dense vectors are usable).
    - `index_state.embeddings.backends.lancedb.available` must be false.
    - Retrieval must either fall back to another backend or Dense, without crashing.
- Manifest mismatch:
  - If an artifact exists on disk but is missing from manifest (strict mode):
    - validation should fail loudly
    - retrieval should treat it as unavailable and surface a clear message rather than guessing.

### 7.8.8 Final Phase 7 audit (mandatory)

- After all Phase 7 tasks land, perform a focused audit of **search** and **embeddings** code/tests:
  - scan for any remaining manifest-by-pass reads in strict mode
  - confirm denseVectorMode and ANN target selection are applied consistently
  - review tests for missing lane assignments or optional-dependency guards
  - update any additional files or tests discovered during the audit



## Mapping: Where this work fits in the repo

### ANN backends
- LanceDB:
  - Build: `tools/build-embeddings/lancedb.js`
  - Runtime: `src/retrieval/lancedb.js`, `src/retrieval/ann/providers/lancedb.js`, `src/shared/lancedb.js`
- HNSW:
  - Build: `tools/build-embeddings/hnsw.js`
  - Runtime: `src/shared/hnsw.js`, `src/retrieval/ann/providers/hnsw.js`, `src/retrieval/cli-index.js`
- SQLite vector extension:
  - Build: `tools/build-embeddings/sqlite-dense.js`
  - Runtime: `tools/vector-extension.js`, `src/retrieval/sqlite-helpers.js`

### Artifact contract / manifest
- Contract docs:
  - `docs/contracts/public-artifact-surface.md`
  - `docs/contracts/artifact-schemas.md`
- Schema code:
  - `src/contracts/registry.js`
  - `src/contracts/schemas/artifacts.js`
- Manifest tooling:
  - `tools/build-embeddings/manifest.js`
  - `src/shared/artifact-io/manifest.js`

---

## Addendum: Strict manifest compliance requirements

This addendum is **mandatory** for Phase 7 completeness.

### A. Strict mode must not guess filenames

Any code path that loads artifacts in strict mode MUST NOT:
- `fs.readFile(path.join(dir, 'dense_vectors_uint8.json'))`
- check for `dense_vectors_hnsw.bin` via guessed filename
- scan directories for `.lancedb`

Instead, strict mode MUST:
- load manifest (`pieces/manifest.json`)
- resolve artifact paths through `resolveArtifactPresence()`

### B. Non-strict fallback is allowed only as a temporary compatibility bridge

If non-strict mode is supported:
- It should be explicitly gated by a CLI flag (e.g., `--non-strict`) or an internal option.
- It should emit a warning that strict contract is being bypassed.

---

## Fixtures list

Use these fixtures in tests. Prefer deterministic, small fixtures; do not introduce “random” corpora that make ANN results flaky.

### Existing fixture repos already in-tree
- `tests/fixtures/sample/`  
  - Primary small deterministic fixture repo used broadly in existing tests.

### Phase 7 fixture repos to add (or verify) under `tests/fixtures/embeddings/`

If these directories do not exist yet, Phase 7 must create them exactly as specified.

1. `tests/fixtures/embeddings/basic-repo/`
   - Purpose: baseline end-to-end embeddings + ANN build on a tiny repo.
   - Must include:
     - At least 2 small code files (e.g., `src/a.js`, `src/b.py`)
     - At least 1 prose file (e.g., `README.md`)
   - Expected behavior:
     - Both `index-code` and `index-prose` produce chunk_meta and dense vectors artifacts.
     - ANN backends can be built if optional deps exist.

2. `tests/fixtures/embeddings/missing-vectors/`
   - Purpose: validate that “missing code/doc vectors” are handled deterministically (zero-fill), and merged vectors normalize correctly.
   - Must include:
     - A small code file with no doc/comments (so `docVector` can be missing/empty in some build paths)
     - A prose file that produces doc-only content
   - Expected behavior:
     - `dense_vectors_doc` for some chunks is all-zero.
     - Merged vector is normalized and non-NaN.
     - ANN builders do not crash on many identical doc vectors.

3. `tests/fixtures/embeddings/quantization-caps/`
   - Purpose: validate quantization clamping and “no wrap” invariants.
   - Must include:
     - A repo with enough chunks to exercise vector writing (even 5–10 chunks is fine).
     - A repo-local config that intentionally sets `quantization.levels` out of range (e.g., 9999).
   - Expected behavior:
     - Artifacts contain only 0..255 values.
     - `embeddingIdentity.quantization.levels` reflects the **clamped** effective value.

### Stub embeddings mode
To keep tests deterministic and fast, use stub embeddings wherever possible:
- Environment: `PAIROFCLEATS_EMBEDDINGS=stub` (or the repo’s equivalent stub toggle)
- Requirement:
  - Stub embeddings must produce deterministic vectors based only on input text and requested dims.
  - They must support both code and prose modes.

## Compat migration checklist Phase 7

Phase 7 intentionally adds fields and manifest entries. It must remain safe to run against older builds and older queue payloads.

Checklist:

- [ ] **Do not rename dense vector filenames on disk.**  
  Keep:
  - `dense_vectors_uint8.json`
  - `dense_vectors_doc_uint8.json`
  - `dense_vectors_code_uint8.json`  
  Phase 7 may add optional metadata fields to these JSON objects, but must not change filenames.

- [ ] **Queue payload versioning is explicit and safe.**
  - New jobs must include `embeddingPayloadFormatVersion: 2`.
  - Worker must either:
    - accept v1 payloads and upgrade them with a warning, or
    - refuse v1 payloads with a clear error message that points to remediation.
  - Never “silently reinterpret” ambiguous fields without logging.

- [ ] **index_state fields are additive.**
  - Preserve existing `index_state.embeddings.enabled/ready/service/mode` semantics.
  - Add new fields (`pending`, `embeddingIdentity`, `embeddingIdentityKey`, `backends`) without breaking older readers.

- [ ] **Strict manifest compatibility.**
  - Older builds may not include embedding artifacts in `pieces/manifest.json`.
  - In strict mode, treat missing manifest entries as “artifact unavailable” and surface a clear validation error (do not guess filenames).
  - If non-strict mode is supported, it may fall back to guessed filenames but must warn.

- [ ] **Optional dependencies remain optional.**
  - If `hnswlib-node` is not installed:
    - Build should skip HNSW gracefully.
    - Manifest must not list HNSW artifacts.
    - Retrieval must not advertise HNSW as available.
  - If `lancedb` is not installed:
    - Build should skip LanceDB gracefully.
    - Manifest must not list LanceDB artifacts.
    - Retrieval must not advertise LanceDB as available.
  - If `sqlite-vec` is not available:
    - Build should skip sqlite-vec ANN tables/markers.
    - Manifest must not list sqlite-vec markers.
    - Retrieval must not advertise sqlite-vec as available.
  - **Tests for optional deps must skip (not fail) when deps are missing**, with a clear skip message.
    - Document this rule for all optional-dep tests in `docs/testing/truth-table.md` (or equivalent testing guide).
    - Centralize skip checks in `tests/helpers/optional-deps.js` and reuse across tests.

- [ ] **Quantization clamp is allowed to invalidate caches.**
  - If an out-of-range `levels` value previously produced incorrect artifacts, Phase 7 clamp is a correctness fix.
  - Any resulting cache invalidation is expected; document it and ensure failures are clear (“identityKey changed”).

## Artifacts contract appendix

This appendix consolidates the *minimum* contract required for Phase 7 so implementers do not need to cross-reference multiple docs while coding. It is additive with (and must not contradict) `docs/contracts/public-artifact-surface.md`.

### A. Dense vector artifacts

These artifacts are JSON objects whose `vectors` field contains the quantized vectors.

#### A.1 `dense_vectors`  
- Manifest name: `dense_vectors`  
- On-disk file: `dense_vectors_uint8.json`

#### A.2 `dense_vectors_doc`  
- Manifest name: `dense_vectors_doc`  
- On-disk file: `dense_vectors_doc_uint8.json`

#### A.3 `dense_vectors_code`  
- Manifest name: `dense_vectors_code`  
- On-disk file: `dense_vectors_code_uint8.json`

#### Required keys (all three)
- `dims` (int)  
- `vectors` (array)  
- `scale` (number)

#### Optional keys (recommended in Phase 7)
- `model` (string or null)
- `minVal` (number)
- `maxVal` (number)
- `levels` (int)
- `quantization` (object, if you want a structured form)
- `embeddingIdentityKey` (string)
- `createdAt` (ISO timestamp)

#### Vector invariants
- For every vector `v` in `vectors`:
  - `v.length === dims`
  - every element is an integer in `[0, 255]`
- If a vector is missing upstream (no doc text, etc), zero-fill is allowed but must be deterministic.

---

### B. HNSW artifacts

HNSW consists of a binary index file plus a JSON meta file.

#### Names and paths (merged/doc/code)
- `dense_vectors_hnsw` → `dense_vectors_hnsw.bin`
- `dense_vectors_hnsw_meta` → `dense_vectors_hnsw.meta.json`
- `dense_vectors_doc_hnsw` → `dense_vectors_doc_hnsw.bin`
- `dense_vectors_doc_hnsw_meta` → `dense_vectors_doc_hnsw.meta.json`
- `dense_vectors_code_hnsw` → `dense_vectors_code_hnsw.bin`
- `dense_vectors_code_hnsw_meta` → `dense_vectors_code_hnsw.meta.json`

#### B.1 HNSW meta required keys
- `dims` (int)
- `count` (int)
- `space` (string; e.g. `cosine|l2|ip`)

#### B.2 HNSW meta optional keys (recommended)
- `efSearch` (int)
- `m` (int)
- `efConstruction` (int)
- `expectedModel` (string; legacy, if present)
- `identityKey` or `embeddingIdentityKey` (string)
- `createdAt` (ISO timestamp)
- quantization metadata (`minVal/maxVal/levels` or equivalent)

#### B.3 HNSW binary file invariants
- The `.bin` file is treated as an opaque artifact for the contract.
- It MUST be discoverable via the manifest in strict mode.
- `.bak` files are implementation details and must not be separately listed in the manifest.

---

### C. LanceDB artifacts

LanceDB consists of a directory plus a JSON meta file.

#### Names and paths (merged/doc/code)
- `dense_vectors_lancedb` → `dense_vectors.lancedb/`
- `dense_vectors_lancedb_meta` → `dense_vectors.lancedb.meta.json`
- `dense_vectors_doc_lancedb` → `dense_vectors_doc.lancedb/`
- `dense_vectors_doc_lancedb_meta` → `dense_vectors_doc.lancedb.meta.json`
- `dense_vectors_code_lancedb` → `dense_vectors_code.lancedb/`
- `dense_vectors_code_lancedb_meta` → `dense_vectors_code.lancedb.meta.json`

#### C.1 LanceDB meta required keys
- `dims` (int)
- `count` (int)
- `metric` (string; e.g. `cosine|l2|dot`)

#### C.2 LanceDB meta additional keys (recommended)
- `table` (string; table name)
- `idColumn` (string; must match how IDs are stored, typically `id`)
- `embeddingColumn` (string; column containing vector embedding)
- `identityKey` or `embeddingIdentityKey` (string)
- `createdAt` (ISO timestamp)
- quantization metadata (`minVal/maxVal/levels` or equivalent)

#### C.3 LanceDB directory invariants
- The directory MUST be discoverable via the manifest in strict mode.
- Directory contents are considered backend-specific implementation details, but must remain stable enough for readers to open.

---

### D. Manifest entry invariants

Every manifest entry must include:
- `name` (string; canonical artifact name)
- `path` (string; relative to the indexDir)
- `format` (string; one of `json|jsonl|bin|dir`)
- `bytes` (int)  
  - For `dir` entries, `bytes` may be omitted. If present, it must be deterministic.

Recommended fields:
- `sha256` for file entries (`json`, `jsonl`, `bin`)

---

### E. Cross-artifact invariants

- If `index_state.embeddings.ready === true` then the manifest MUST contain `dense_vectors`.
- If an ANN backend is reported as available in `index_state.embeddings.backends.*.available === true`, then the corresponding artifact entries MUST exist in the manifest.

--- 

# Phase 9 -- Symbol identity (collision-safe IDs) + cross-file linking 

## Objective

Eliminate correctness hazards caused by non-unique, name-based joins (notably `file::name` and legacy `chunkId` usage) and replace them with a collision-safe identity layer. Use that identity to produce:

1) **Stable, segment-aware node identity** (`chunkUid`, `segmentUid`, `virtualPath`) that survives minor line shifts and prevents collisions across:
   - same-name declarations in different files,
   - same-name declarations inside different segments of the same container file,
   - repeated definitions (overloads, nested scopes, generated code patterns).

2) **A canonical symbol identity and reference contract** (`symbolKey`, `signatureKey`, `scopedId`, `symbolId`, `SymbolRef`) that:
   - is deterministic,
   - is language-agnostic at the storage boundary,
   - preserves ambiguity instead of forcing wrong links.

3) **Cross-file resolution that is import-aware and ambiguity-preserving**, using bounded heuristics and explicit `state` / `confidence` fields.

4) **First-class symbol graph artifacts** (`symbols`, `symbol_occurrences`, `symbol_edges`) that enable downstream graph analytics and product features without re-parsing code.

5) **Fail-closed identity and symbol joins:** no `file::name` fallback in strict mode; ambiguous resolutions are preserved, not guessed.

---
# Phase 9 -- Symbol identity (collision-safe IDs) + cross-file linking (detailed execution plan)

